{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e1e8ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b03b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98399e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 32, 32, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4d3388b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "572170c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2d3779340d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(X_train[1],cmap=\"Accent_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07907c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcvUlEQVR4nO2da2yd13Wm33UuvOtGUhdaV1uWXct2Yrus7UwGSeo0hetk4ORHguZHx1N46v5ogAmQmYGRAZrMv8xgkiLADIIqEyNK4eaCJkHcNJPE4yZ1DEyd0I6l2JIsS7JkXagbJYoXkTy31R88BmR3v4s0L4ea7vcBBFJ7nf196+zzLX7n7PestczdIYT4l09hpR0QQrQGBbsQmaBgFyITFOxCZIKCXYhMULALkQmlxUw2swcBfBlAEcD/dvcvRI/v7evzLVu3JW0z09N0XrVSSY53d3fTOcVyOXJlYVwvKqVZYEw7Gc1YhCNLfDy+wNfL0i/YkWCpFrKKzI2TJ05gZORi8pALDnYzKwL4XwA+BOAUgF+Z2VPufoDN2bJ1G3749D8kba8dfIWea/jMqeT4fffdR+f0rt9IbXWP3tAES98ggRQG39ITnc/QSI4XbGFXqRlfq0JhaZ93I/jOR71ep7ZW/iFY6PdSitFrRmyFAl97th4PvP9f0TmLeRt/L4Aj7n7M3SsAvgXg4UUcTwixjCwm2DcDOHnN/081x4QQ1yGLCfbUe49/9h7HzB4zsyEzG7o0MrKI0wkhFsNigv0UgK3X/H8LgDNvf5C773H3QXcf7O3rW8TphBCLYTHB/isAu8zsRjNrA/CHAJ5aGreEEEvNgnfj3b1mZp8C8BPMSm9PuDvfUgcAGNzTO4/1enoXGQAaxBZtjDb44VAnu+rNo1KLLXGGYLirHtre+bmiXeRo1zeUwxawHJEf0W58ZFsI0XNuBBdPZIteFq4lgC6kLWA33oNre1E6u7v/CMCPFnMMIURr0DfohMgEBbsQmaBgFyITFOxCZIKCXYhMWNRu/DvFzNBWbksbg+SURiMtangwJ7LFIsnCZLmlJpSoAlmRJ8JE5wrkpCARJpKhFpIwslB5bakTkaLjFYvFhR0zMpLnHcmDbH2jpdCdXYhMULALkQkKdiEyQcEuRCYo2IXIhJbuxnvDMTNTS9qqtWhnN73FWK3yOdVKUMaowHdU4/JN73zXNN4pXmiyS5DUQiZaMCdKQioWg8Qg4+vIEjWi8lLRk46SQkLoegRTFnquQE2IkqhapfHozi5EJijYhcgEBbsQmaBgFyITFOxCZIKCXYhMaK305o5GLS29RbJFsZR2M5S8otppDeIDAATSG5PlCpHkEslrof8Lk+WMZbwECS1RcseJ469T2xsnT1Lb4D33JMc7OjronIZzWS5Sw0IZjS1HMGehePDCBLlLIMryktch1J1diExQsAuRCQp2ITJBwS5EJijYhcgEBbsQmbAo6c3MjgMYx2x3m5q7D0aPLxSAjjaShRRJXsX036SOznY6p7OjHHgSZSdx+YfJecvRximaV6nMUNuLL76cHB/Ywrtp37xzC7UdPXKU2r665y+p7T//p88kx99z/310Ti3KiCsEr1nYzousI6lrCPAsy/B44BIagPC2ytyP5MaopiBjKXT233X3i0twHCHEMqK38UJkwmKD3QH81MxeMLPHlsIhIcTysNi38e919zNmtgHA02Z2yN2fvfYBzT8CjwHA5i1bF3k6IcRCWdSd3d3PNH+eB/B9APcmHrPH3QfdfbCvr28xpxNCLIIFB7uZdZvZqjd/B/D7ANJbwUKIFWcxb+M3Avh+UyIqAfhrd//xXJO4nMBll3IpPamtzLO1oi49UZehYlBEkboeyWv8VGG7o0h2KZW4jwdeSf+9/eHf/S2d88d//Ai1eSBFHjn8KrX99MfpS+Fdd+ymc1atXkVt1SBTsWY8p4zJWmF3sAVWgIwFuyXOs1tAOt+Cg93djwF490LnCyFai6Q3ITJBwS5EJijYhcgEBbsQmaBgFyITWlpw0gAUiJQTZZuViJxQiMr41blUE4ogxQVkNQVSTZgJFVALet9F2XK33npzcvzJJ/+Kzjl0gH89Ysc2/q3HqckJavvx//m75PgtN++gcx768IeprXsVl+UawQtQJeO1oABnIbhCSgucF10GTiTYRiOQFJktuBZ1ZxciExTsQmSCgl2ITFCwC5EJCnYhMqGlu/EAUCTFszzYPYendx5LwbY0O8/cBLvgzLDAP5m0VRPCbk109xYASkS6KAUqw9Avn6e2F3/FbZXpKWprVNO2rwV16/YNDVHbfb9zP7e9/33UtnpgQ3I8LBdXCJKhAgHIgtclyq1htqVuUaU7uxCZoGAXIhMU7EJkgoJdiExQsAuRCQp2ITKh5dIbLQBH5DWAy0ZF0hYqmhO5AAC1IPmAtScqBQXvLCgm58FzjrSao0eOUNver389OX789WN0TmdHG7XNTF2ltmLQsqtBpNThM2fonH8c51Le2aMnqe3ggYPU9sDDH0mOb9y+nc5Z1c2TbgoF3lasHFwHQbcpMLm3UODhGSVDMXRnFyITFOxCZIKCXYhMULALkQkKdiEyQcEuRCbMKb2Z2RMAPgLgvLvf0RzrBfBtADsAHAfwCXe/PPfpHPVGWr6KJK86sUXtk+qRvhbYKlXux5Wx8eT42tVr6Jy2ciC9Bc/ZWd8iAK+/doLbjr6RPl7Q76hY4OcqBzaWYQcApXJaoopes8rMDLeNjVHb/33qKWp79h9+nhzfuitdqw8Abty5i9p2bN9BbVu28np9O27eSW3renuT44EwC5A4ijTb+dzZvw7gwbeNPQ7gGXffBeCZ5v+FENcxcwZ7s9/6pbcNPwxgb/P3vQA+urRuCSGWmoV+Zt/o7sMA0PyZrhAghLhuWPYNOjN7zMyGzGxoZGRkuU8nhCAsNNjPmdkAADR/nmcPdPc97j7o7oN9fX0LPJ0QYrEsNNifAvBI8/dHAPxgadwRQiwX85HevgngAwD6zewUgM8B+AKA75jZowDeAPDx+ZzMwYWBapU16gFqtXQGlYdl/GI/GPVA8pqerqTH27hkVCryLKmoN9TIRf6R58DLB6htcmIyOd7e0c79qE1TU2c7z4grgD+3ru6e5PjUDC8sGl0DMzPcxygz78zIheT42Yv0zSheeZm3w+rs7KK2Unsntd16553U9uGP/Jvk+ODvDNI5BZJNGSnOcwa7u3+SmD4411whxPWDvkEnRCYo2IXIBAW7EJmgYBciExTsQmRC6wtOEpiUAABlkkG1UBpRhl2dyz9O8pCmZ3ihxM5A8ioV+fIfOMDln5/97O+p7fLltGQXLC8tDgnEPfPWreaFGUtt6efdaHCZbFUPl646ezqozS9FPdZIlmUtLaMCwNTVCW6b4LaxSX4d7D90mNteSRfM/PePPkrnvOc970mO10lRVEB3diGyQcEuRCYo2IXIBAW7EJmgYBciExTsQmRCa6U3B5yk5VQqXAox0tjq6lUu47A5QCzl1WpcepueTmeU1as8I6uni0tGlQqXjI4e5VLN+Qtnqa2tnO431mhweQ1Bz7aONt6/LGi1BxA5zwNpc/36LdS288Yd1HZm5By12dV0kVAQSQ4AZqbSrzMAtBV5FmB7ia9VpcbPd/hgWmb9y6/8Tzrn4Cv7k+MXL6az/ADd2YXIBgW7EJmgYBciExTsQmSCgl2ITGjpbnylWsHJkyeTtrGgvQ9LXHnjjXSrIwA4evQotUXJAtt2bKO2K2OjyfGxK1fonDt2305t01d54sQvnnuW2iYn+VqVy+nd4nIxUCe6ggSUMp9XD5SLRiOtrkRJN5N05xwYPj9MbZUarwHolr52aoEfwUY9anWuXEQKUBvxAwCq5HocPnGEzvnJ315Mjl8ZHaVzdGcXIhMU7EJkgoJdiExQsAuRCQp2ITJBwS5EJsyn/dMTAD4C4Ly739Ec+zyAPwHw5rfuP+vuP5rrWJcvX8LffO9bSVt30FZncjxd9+vsmVN0zq/38Rpuh17lkkb/+l5qY4kfUZ22G3dspzYLevUcPsBbPJWCBlYloht1dfCEnEaDS2iVapCgRGryAUCVJH5Esmdlhktow6fPUNtM0DbK2tJJT1eDc5ULPFGqGNwfCwikt+C26mRNys7lwRkiA3sgKc7nzv51AA8mxv/C3e9q/psz0IUQK8ucwe7uzwK41AJfhBDLyGI+s3/KzPab2RNmtm7JPBJCLAsLDfavANgJ4C4AwwC+yB5oZo+Z2ZCZDU0FXw8VQiwvCwp2dz/n7nV3bwD4KoB7g8fucfdBdx/sDL6DLYRYXhYU7GY2cM1/PwaAb30LIa4L5iO9fRPABwD0m9kpAJ8D8AEzuwuAAzgO4E/nc7KpqavYt/+FpG33LbfQeeOj6Syvfzz8Op1z5txlamuASysnXueZdFdG05lGnYGsdfJ17mNHKVj+GpdQOqJWWUQfjOrkzQQyVCQnlYq85poT/3s6+Lu77ragXt8M9z+iTmTKqnPZ0IL2YFbia99WiiS7oC0TOV+QKAc4OR5XZecOdnf/ZGL4a3PNE0JcX+gbdEJkgoJdiExQsAuRCQp2ITJBwS5EJrS04GS9VsfYaLo441TQymn8yigZ5/KaBRlD7e3t3NbGpSGrpzPzikH2WkeUoRYUbKwH2WaFMn/ZCpaWw6aD9lqoB1JTIL1FGWCb1m9KjrcHrbcagRw2HvgftQ5jGWVtxWANPSiyGchyrLUZALQXuEzZRiTHeiNoUUUz/bgPurMLkQkKdiEyQcEuRCYo2IXIBAW7EJmgYBciE1oqvZXLZQxsHEjaCoFssaG/Lzl+w8ANdE4jeGoTU1yqiYpHdhD1ZPxCOhsOAM6fOk1ttWmeyVULZLnpoLdZtZZ+bqVAQmsY/5vf3cmlyA19/dRm5OW8PDJC59SDApYoc+mqMyhWOjWWlnrbgsxBI/IlEEtv1SBTsVTixyyTopgl49dwlfkR9JvTnV2ITFCwC5EJCnYhMkHBLkQmKNiFyISW7sb39/Xh3/3bR5K2l4aep/OuXErvdleCumrtXT3UVqoGySmFoIgXST64epn30FgV7I5u2r6N2ort/KUZGR+ltktX0q2yKjW+i9xo8Ofcs2Y1P9coT0Q6fSbdrqkYJPFs2riR2tauWUVt3RXuI9s9Hx0bp3PKQaJUnckMAGaC1kseJBt1NNLXSClI1mHJXAXtxgshFOxCZIKCXYhMULALkQkKdiEyQcEuRCbMp/3TVgDfALAJQAPAHnf/spn1Avg2gB2YbQH1CXfnWgyASrWK4dNpSaYctBJaszotrdQDqaPYxuWTKHHCghpel86eTY6ffIO3jLJpnrRSq3DpcF3/Gmrr6OB13AY2ppOGJq/y5B9e6QwYvniB2s5cOEdtha60jzfdsovOufmmndTWE7TYqgRr3EuSqF577Sidc/ESv4wLpL0WgCiNB1XWrgkASNJTW3A81pYrEI7ndWevAfiMu98G4H4Af2ZmuwE8DuAZd98F4Jnm/4UQ1ylzBru7D7v7i83fxwEcBLAZwMMA9jYfthfAR5fJRyHEEvCOPrOb2Q4AdwN4HsBGdx8GZv8gANiw5N4JIZaMeQe7mfUA+C6AT7t7uodyet5jZjZkZkMTE+mvcgohlp95BbuZlTEb6E+6+/eaw+fMbKBpHwBwPjXX3fe4+6C7D/b08O+rCyGWlzmD3cwMs/3YD7r7l64xPQXgzayWRwD8YOndE0IsFfPJensvgD8C8Bsze6k59lkAXwDwHTN7FMAbAD4+14Gmp6dx6NBrSVvvKl7rrIO0x+H5PUChxOWpap0LFKNj/KPG+HRaPrkcHG8mals0xiWemVJQzwy8Pt0M0X8mgky/jq5ualvbu5ba2rq5hLlmXW9yfPPWrXxO7zpq6wrO1R34v2nb9uT4tkDme+4Xz1Hb6aCmYNRSKsosdJL1FkwJJTbGnMHu7s+Bx9UHF3BOIcQKoG/QCZEJCnYhMkHBLkQmKNiFyAQFuxCZ0NKCkx0dXbjl9ruStrOnjtN5TrLb1pOMJgAYuGELtZ05m/z+DwDg0BHux8TkVHK8vYcXQxwZTbcfAoD2Gs+Emg50lygbiklsk+BZgD1reaHH/mAdJ6d41t5MNf2aHT3N5caOi1ep7c7bb6e2Bx7golAfkQBrM1wSXbOKtxX7xt691FappK8PACgU+WtdJ22jKkE7KSft0hpBGzXd2YXIBAW7EJmgYBciExTsQmSCgl2ITFCwC5EJLZXeCsUSutak5bLpEyfovEYlLUHcNsAzqHbtfhe1XZn+NbV1reKFHvv616cNQbYTk6AAoBEUnBwZ5zLO5g1pOQkAbr4pLRtZO88MW9fXT23t7bzQYyS9XRpN1zcZneFSZGWGr9XIZS6X/nrfC9T27jvT10FnUMBy7OootdUavLhlpc7lvKiQaa2Rft4eyK8si07SmxBCwS5ELijYhcgEBbsQmaBgFyITWrob32g0MDE5mbQVCrz9k1u6KlaxxN3v7uG7z4UC/xtXD3ZAC2TX/Y533U3nrOvjSSZjV3hSSBl8Z3pT31pq29Cfto2PjdI509Pj1NZJ2jgBwIYb+C5+ZTJ9vitVXuNvYporEK8c4mv1xul0XUMAGB1Lt+xat5bXu3v5Va7WTFS4H7UqT3axOr++zd75PbfUln5djMQKoDu7ENmgYBciExTsQmSCgl2ITFCwC5EJCnYhMmFO6c3MtgL4BoBNABoA9rj7l83s8wD+BMCF5kM/6+4/io7ljTqqU2nprTbD648V6ul2RyWQXkcAZq5yOWlynCdjXB65SG3nz59Ljt/57nvonFVredJKbz+Xrn7r5puo7eTrXGo6dSGdMPLSvn10zpXx9GsCAL/3oQ9R261387pwB0+k/Zis8/UtdvIWYA8+9CC1Df72b1Mbaw1VDxKUfvqTX1BbrcZr+VXrPEmmUeUtuwrF9D03lIhJwgurTQfMT2evAfiMu79oZqsAvGBmTzdtf+Hu/2MexxBCrDDz6fU2DGC4+fu4mR0EsHm5HRNCLC3v6DO7me0AcDeA55tDnzKz/Wb2hJnxryQJIVaceQe7mfUA+C6AT7v7GICvANgJ4C7M3vm/SOY9ZmZDZjY0McG/KimEWF7mFexmVsZsoD/p7t8DAHc/5+51d28A+CqAe1Nz3X2Puw+6+2BPT89S+S2EeIfMGew2+836rwE46O5fumZ84JqHfQzAy0vvnhBiqZjPbvx7AfwRgN+Y2UvNsc8C+KSZ3QXAARwH8KdzHajRcMyQFkqdQY20ifG0bHH0GK9bF9WSi7LNpoK2QN3d6TZPkdxRNC4PXiQyGQBc6uf+WzvPRBu9ml7fqKZdZ89aaiv18BZbpy6m68wBwJUpUletwJtXdXXxNlobN2zntoGd1FYkmYoT4/wjZcN4fbpiicuDQZk5VOuBkUjIUQYbq0G3KOnN3Z8DkDprqKkLIa4v9A06ITJBwS5EJijYhcgEBbsQmaBgFyITWlpw0r2BmZl0ZtC6Xp4ddtvttyXHiyX+t2p0jMtCY5M8I66ri0srd96xOzm+c+eNdM7Q0C+p7dLFdDFEAHhhiMuDvb38m8mlYlquufWWXXTOhk081aFe40UUDx16lc+rpF/nDl53EaUaz3wcPXOE2l5/JTgoKWRar/Gstw09/HirS7zlVdV5ZttUkMFWqaXlMi68AUzni+bozi5EJijYhcgEBbsQmaBgFyITFOxCZIKCXYhMaHmvtynSV6y3bzWdt37j+uR4tcoL/F2+zKWrSZIZBgBdHTzjad3qtI+V4HiVKW7bvJH3gds0wG31OpeNjk+cSo739abXEADa2vhzjrKo2km/sdljpi+tySALsL3MJa/6FJdSLw3z7MdKLX2+9naefbdr2wC17V/FpdnzF3nhzpLxtaqS7LZIRosy4hi6swuRCQp2ITJBwS5EJijYhcgEBbsQmaBgFyITWpz15pipp7Oo6sHfHS+k3XTjslCh1MUdKXD55NIol0+On0jLWjfdxLPePFhiD9STvv5N1FYN+oZduJiWNgc284KNV6d5kc3hC7w3W3cgQ7WRopjlNi6vdazmRTbLa/l69O/4LT6PyIq1Gl/DjjUbqG3X4depbfjnf09tdZLtCQAlW8p7Lr+odGcXIhMU7EJkgoJdiExQsAuRCQp2ITJhzt14M+sA8CyA9ubj/8bdP2dmvQC+DWAHZts/fcLdefYJgGKphHVr0zud3T28rlpbOd0WqFwKdh6NtxLasf12amtv4zvCGzf0J8e37eT13Vb18aSKCxfOBfN4Tb4oB2JwXfp8a1bxRCMr8SSNE2dOU9vRY4epbXo6nQDk4Ek8E0HS0OHjaSUEACZq/DLeeEO6vl4pqAnX4Bv12HX7XdR2/MRJajt6+BC1FZ21f+I+lkrp51wocDVpPnf2GQAPuPu7Mdue+UEzux/A4wCecfddAJ5p/l8IcZ0yZ7D7LG92wSs3/zmAhwHsbY7vBfDR5XBQCLE0zLc/e7HZwfU8gKfd/XkAG919GACaP/k3EYQQK868gt3d6+5+F4AtAO41szvmewIze8zMhsxsaHKSf54QQiwv72g33t1HAfwcwIMAzpnZAAA0fyabjbv7HncfdPfB7m7eg10IsbzMGexmtt7M1jZ/7wTwewAOAXgKwCPNhz0C4AfL5KMQYgmYTyLMAIC9ZlbE7B+H77j7D83s/wH4jpk9CuANAB+f60Bd3atwz33vT9rKRe5KA+l6YfU6r2fmwfF27b6b2u68Z5DaOtrTx2T11gDghu07qO38Od7+6dix1wI/uFTWSyS7YpAgYcFa3bR9K7WhwZM7Rs4RGYq/ZLhyeYTaVvdwmdL7+6jt3IljyfG+DXyLad1q/g70lp07qO3sbbdw28nj1FYjiU2FQB6k0lugy84Z7O6+H8A/iw53HwHwwbnmCyGuD/QNOiEyQcEuRCYo2IXIBAW7EJmgYBciEyxq77PkJzO7AODNXj39AHiBs9YhP96K/Hgr/7/5sd3dk72+Whrsbzmx2ZC7c1FbfsgP+bGkfuhtvBCZoGAXIhNWMtj3rOC5r0V+vBX58Vb+xfixYp/ZhRCtRW/jhciEFQl2M3vQzF41syNmtmK168zsuJn9xsxeMrOhFp73CTM7b2YvXzPWa2ZPm9lrzZ+8Aufy+vF5MzvdXJOXzOyhFvix1cx+ZmYHzewVM/sPzfGWrkngR0vXxMw6zOyXZrav6cd/bY4vbj3cvaX/ABQBHAVwE4A2APsA7G61H01fjgPoX4Hzvg/APQBevmbsvwN4vPn74wD+2wr58XkA/7HF6zEA4J7m76sAHAawu9VrEvjR0jXBbMO2nubvZQDPA7h/seuxEnf2ewEccfdj7l4B8C3MFq/MBnd/FsCltw23vIAn8aPluPuwu7/Y/H0cwEEAm9HiNQn8aCk+y5IXeV2JYN8M4NrKBqewAgvaxAH81MxeMLPHVsiHN7meCnh+ysz2N9/mL/vHiWsxsx2YrZ+wokVN3+YH0OI1WY4irysR7KlSGislCbzX3e8B8AcA/szM3rdCflxPfAXATsz2CBgG8MVWndjMegB8F8Cn3X2sVeedhx8tXxNfRJFXxkoE+ykA19Y62gLgzAr4AXc/0/x5HsD3MfsRY6WYVwHP5cbdzzUvtAaAr6JFa2JmZcwG2JPu/r3mcMvXJOXHSq1J89yjeIdFXhkrEey/ArDLzG40szYAf4jZ4pUtxcy6zWZ7RJlZN4DfB/ByPGtZuS4KeL55MTX5GFqwJmZmAL4G4KC7f+kaU0vXhPnR6jVZtiKvrdphfNtu40OY3ek8CuC/rJAPN2FWCdgH4JVW+gHgm5h9O1jF7DudRwH0YbaN1mvNn70r5MdfAfgNgP3Ni2ugBX78a8x+lNsP4KXmv4davSaBHy1dEwDvAvDr5vleBvDnzfFFrYe+QSdEJugbdEJkgoJdiExQsAuRCQp2ITJBwS5EJijYhcgEBbsQmaBgFyIT/gnw5+tU6BMnfgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42a33c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
    "hidden=[100]*20\n",
    "for n_hidden in hidden:\n",
    "    model.add(keras.layers.Dense(n_hidden, activation=\"elu\",\n",
    "                                   kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "beb294d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 3072)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               307300    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 500,210\n",
      "Trainable params: 500,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ee07099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\",\n",
    "                                                      save_best_only=True)\n",
    "run_index =1\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\",\"run_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7acd0cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-de78eb4ff17791d5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-de78eb4ff17791d5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49984d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 24s 10ms/step - loss: 3.5798 - accuracy: 0.1726 - val_loss: 2.1035 - val_accuracy: 0.2402\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 2.0412 - accuracy: 0.2548 - val_loss: 1.9808 - val_accuracy: 0.2724\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.9334 - accuracy: 0.2942 - val_loss: 1.8828 - val_accuracy: 0.3080\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.8557 - accuracy: 0.3213 - val_loss: 1.8751 - val_accuracy: 0.3280\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.7982 - accuracy: 0.3464 - val_loss: 1.7732 - val_accuracy: 0.3570\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.7415 - accuracy: 0.3670 - val_loss: 1.7407 - val_accuracy: 0.3616\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.7019 - accuracy: 0.3835 - val_loss: 1.7367 - val_accuracy: 0.3636\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6650 - accuracy: 0.3991 - val_loss: 1.6493 - val_accuracy: 0.4014\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.6344 - accuracy: 0.4100 - val_loss: 1.6447 - val_accuracy: 0.4092\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.6100 - accuracy: 0.4214 - val_loss: 1.7001 - val_accuracy: 0.3882\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5853 - accuracy: 0.4264 - val_loss: 1.6396 - val_accuracy: 0.4092\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5610 - accuracy: 0.4382 - val_loss: 1.6134 - val_accuracy: 0.4170\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5384 - accuracy: 0.4443 - val_loss: 1.6334 - val_accuracy: 0.4140\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5244 - accuracy: 0.4507 - val_loss: 1.5877 - val_accuracy: 0.4306\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.5055 - accuracy: 0.4591 - val_loss: 1.5642 - val_accuracy: 0.4396\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4872 - accuracy: 0.4655 - val_loss: 1.5659 - val_accuracy: 0.4408\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4707 - accuracy: 0.4736 - val_loss: 1.5708 - val_accuracy: 0.4416\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4571 - accuracy: 0.4792 - val_loss: 1.5571 - val_accuracy: 0.4486\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4457 - accuracy: 0.4812 - val_loss: 1.5627 - val_accuracy: 0.4458\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4324 - accuracy: 0.4874 - val_loss: 1.5599 - val_accuracy: 0.4530\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4197 - accuracy: 0.4897 - val_loss: 1.5785 - val_accuracy: 0.4456\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4045 - accuracy: 0.4944 - val_loss: 1.5574 - val_accuracy: 0.4564\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3945 - accuracy: 0.5007 - val_loss: 1.5644 - val_accuracy: 0.4400\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3809 - accuracy: 0.5027 - val_loss: 1.5302 - val_accuracy: 0.4534\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3720 - accuracy: 0.5082 - val_loss: 1.5390 - val_accuracy: 0.4700\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3588 - accuracy: 0.5136 - val_loss: 1.5557 - val_accuracy: 0.4496\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3471 - accuracy: 0.5156 - val_loss: 1.5117 - val_accuracy: 0.4684\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3405 - accuracy: 0.5200 - val_loss: 1.5327 - val_accuracy: 0.4608\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3289 - accuracy: 0.5246 - val_loss: 1.5079 - val_accuracy: 0.4680\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3185 - accuracy: 0.5263 - val_loss: 1.6577 - val_accuracy: 0.4352\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3097 - accuracy: 0.5285 - val_loss: 1.5197 - val_accuracy: 0.4774\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2982 - accuracy: 0.5354 - val_loss: 1.5391 - val_accuracy: 0.4624\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2917 - accuracy: 0.5385 - val_loss: 1.5686 - val_accuracy: 0.4604\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2812 - accuracy: 0.5393 - val_loss: 1.5244 - val_accuracy: 0.4724\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2723 - accuracy: 0.5436 - val_loss: 1.5395 - val_accuracy: 0.4678\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2657 - accuracy: 0.5458 - val_loss: 1.5012 - val_accuracy: 0.4814\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2560 - accuracy: 0.5493 - val_loss: 1.5350 - val_accuracy: 0.4706\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2482 - accuracy: 0.5505 - val_loss: 1.5075 - val_accuracy: 0.4818\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2416 - accuracy: 0.5573 - val_loss: 1.5362 - val_accuracy: 0.4756\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2309 - accuracy: 0.5609 - val_loss: 1.4986 - val_accuracy: 0.4850\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2220 - accuracy: 0.5613 - val_loss: 1.5448 - val_accuracy: 0.4740\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2156 - accuracy: 0.5656 - val_loss: 1.5333 - val_accuracy: 0.4754\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2082 - accuracy: 0.5673 - val_loss: 1.6004 - val_accuracy: 0.4560\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1996 - accuracy: 0.5711 - val_loss: 1.5639 - val_accuracy: 0.4742\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1925 - accuracy: 0.5752 - val_loss: 1.5535 - val_accuracy: 0.4778\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1826 - accuracy: 0.5768 - val_loss: 1.5297 - val_accuracy: 0.4754\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1777 - accuracy: 0.5784 - val_loss: 1.5119 - val_accuracy: 0.4782\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1674 - accuracy: 0.5805 - val_loss: 1.5513 - val_accuracy: 0.4834\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1605 - accuracy: 0.5864 - val_loss: 1.5359 - val_accuracy: 0.4772\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1543 - accuracy: 0.5884 - val_loss: 1.5534 - val_accuracy: 0.4840\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1483 - accuracy: 0.5899 - val_loss: 1.5728 - val_accuracy: 0.4754\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.1349 - accuracy: 0.5926 - val_loss: 1.5368 - val_accuracy: 0.4860\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1294 - accuracy: 0.5958 - val_loss: 1.5245 - val_accuracy: 0.4886\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1239 - accuracy: 0.5985 - val_loss: 1.5653 - val_accuracy: 0.4798\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1179 - accuracy: 0.5981 - val_loss: 1.5620 - val_accuracy: 0.4782\n",
      "Epoch 56/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1098 - accuracy: 0.6022 - val_loss: 1.5586 - val_accuracy: 0.4802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1026 - accuracy: 0.6044 - val_loss: 1.5769 - val_accuracy: 0.4794\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0985 - accuracy: 0.6070 - val_loss: 1.5650 - val_accuracy: 0.4842\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0913 - accuracy: 0.6083 - val_loss: 1.5464 - val_accuracy: 0.4754\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0810 - accuracy: 0.6138 - val_loss: 1.5616 - val_accuracy: 0.4818\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d366b98700>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        callbacks=[early_stopping_cb, model_checkpoint_cb, tensorboard_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "955e467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 1.4922 - accuracy: 0.4811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4922479391098022, 0.4810999929904938]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f225fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9ec4f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "hidden=[100]*20\n",
    "for n_hidden in hidden:\n",
    "    model.add(keras.layers.Dense(n_hidden, activation=\"elu\",\n",
    "                                   kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\",\n",
    "                                                      save_best_only=True)\n",
    "run_index =1\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_bn_logs\",\"run_bn_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f574ae67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 46s 15ms/step - loss: 2.2459 - accuracy: 0.2128 - val_loss: 1.9275 - val_accuracy: 0.3044\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.9314 - accuracy: 0.3066 - val_loss: 1.7835 - val_accuracy: 0.3512\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.8312 - accuracy: 0.3399 - val_loss: 1.7069 - val_accuracy: 0.3830\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.7619 - accuracy: 0.3664 - val_loss: 1.6455 - val_accuracy: 0.4040\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.7114 - accuracy: 0.3863 - val_loss: 1.5965 - val_accuracy: 0.4302\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.6630 - accuracy: 0.4059 - val_loss: 1.5633 - val_accuracy: 0.4398\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.6221 - accuracy: 0.4202 - val_loss: 1.5329 - val_accuracy: 0.4532\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.5918 - accuracy: 0.4327 - val_loss: 1.5066 - val_accuracy: 0.4624\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.5655 - accuracy: 0.4438 - val_loss: 1.4908 - val_accuracy: 0.4656\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.5350 - accuracy: 0.4548 - val_loss: 1.4729 - val_accuracy: 0.4730\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5198 - accuracy: 0.4573 - val_loss: 1.4573 - val_accuracy: 0.4840\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.4942 - accuracy: 0.4663 - val_loss: 1.4567 - val_accuracy: 0.4792\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.4736 - accuracy: 0.4760 - val_loss: 1.4406 - val_accuracy: 0.4866\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.4597 - accuracy: 0.4811 - val_loss: 1.4312 - val_accuracy: 0.4862\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.4372 - accuracy: 0.4893 - val_loss: 1.4437 - val_accuracy: 0.4914\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.4281 - accuracy: 0.4938 - val_loss: 1.4162 - val_accuracy: 0.4908\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.4121 - accuracy: 0.5003 - val_loss: 1.4174 - val_accuracy: 0.4994\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.3951 - accuracy: 0.5053 - val_loss: 1.4033 - val_accuracy: 0.5016\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.3842 - accuracy: 0.5075 - val_loss: 1.3979 - val_accuracy: 0.5090\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.3684 - accuracy: 0.5150 - val_loss: 1.4032 - val_accuracy: 0.5048\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.3574 - accuracy: 0.5167 - val_loss: 1.3887 - val_accuracy: 0.5084\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.3455 - accuracy: 0.5235 - val_loss: 1.3849 - val_accuracy: 0.5114\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.3322 - accuracy: 0.5300 - val_loss: 1.3844 - val_accuracy: 0.5124\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.3220 - accuracy: 0.5298 - val_loss: 1.3797 - val_accuracy: 0.5172\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.3127 - accuracy: 0.5358 - val_loss: 1.3706 - val_accuracy: 0.5158\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.3010 - accuracy: 0.5374 - val_loss: 1.3685 - val_accuracy: 0.5230\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.2896 - accuracy: 0.5413 - val_loss: 1.3824 - val_accuracy: 0.5150\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.2864 - accuracy: 0.5433 - val_loss: 1.3745 - val_accuracy: 0.5152\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 1.2747 - accuracy: 0.5456 - val_loss: 1.3646 - val_accuracy: 0.5264\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2684 - accuracy: 0.5484 - val_loss: 1.3598 - val_accuracy: 0.5238\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2529 - accuracy: 0.5555 - val_loss: 1.3743 - val_accuracy: 0.5218\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2471 - accuracy: 0.5577 - val_loss: 1.3682 - val_accuracy: 0.5242\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2405 - accuracy: 0.5583 - val_loss: 1.3692 - val_accuracy: 0.5228\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2286 - accuracy: 0.5640 - val_loss: 1.3708 - val_accuracy: 0.5230\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2231 - accuracy: 0.5652 - val_loss: 1.3674 - val_accuracy: 0.5190\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2169 - accuracy: 0.5666 - val_loss: 1.3698 - val_accuracy: 0.5244\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2036 - accuracy: 0.5721 - val_loss: 1.3674 - val_accuracy: 0.5280\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1959 - accuracy: 0.5730 - val_loss: 1.3659 - val_accuracy: 0.5304\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1950 - accuracy: 0.5760 - val_loss: 1.3645 - val_accuracy: 0.5202\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1802 - accuracy: 0.5801 - val_loss: 1.3853 - val_accuracy: 0.5120\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1734 - accuracy: 0.5857 - val_loss: 1.3644 - val_accuracy: 0.5256\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1736 - accuracy: 0.5833 - val_loss: 1.3683 - val_accuracy: 0.5314\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1662 - accuracy: 0.5871 - val_loss: 1.3722 - val_accuracy: 0.5246\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1592 - accuracy: 0.5859 - val_loss: 1.3916 - val_accuracy: 0.5160\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1560 - accuracy: 0.5912 - val_loss: 1.3638 - val_accuracy: 0.5218\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1537 - accuracy: 0.5904 - val_loss: 1.3524 - val_accuracy: 0.5224\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1328 - accuracy: 0.5995 - val_loss: 1.3566 - val_accuracy: 0.5268\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1336 - accuracy: 0.5999 - val_loss: 1.3817 - val_accuracy: 0.5172\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1269 - accuracy: 0.6002 - val_loss: 1.3773 - val_accuracy: 0.5214\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1122 - accuracy: 0.6038 - val_loss: 1.3725 - val_accuracy: 0.5180\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1059 - accuracy: 0.6060 - val_loss: 1.3785 - val_accuracy: 0.5224\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1071 - accuracy: 0.6070 - val_loss: 1.3807 - val_accuracy: 0.5200\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1003 - accuracy: 0.6098 - val_loss: 1.3826 - val_accuracy: 0.5280\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0993 - accuracy: 0.6083 - val_loss: 1.3723 - val_accuracy: 0.5262\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0938 - accuracy: 0.6143 - val_loss: 1.3854 - val_accuracy: 0.5178\n",
      "Epoch 56/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0824 - accuracy: 0.6152 - val_loss: 1.3806 - val_accuracy: 0.5220\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0791 - accuracy: 0.6188 - val_loss: 1.3765 - val_accuracy: 0.5246\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0729 - accuracy: 0.6218 - val_loss: 1.3948 - val_accuracy: 0.5204\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0689 - accuracy: 0.6181 - val_loss: 1.3815 - val_accuracy: 0.5244\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0614 - accuracy: 0.6245 - val_loss: 1.3979 - val_accuracy: 0.5236\n",
      "Epoch 61/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0505 - accuracy: 0.6271 - val_loss: 1.3932 - val_accuracy: 0.5240\n",
      "Epoch 62/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0491 - accuracy: 0.6291 - val_loss: 1.4010 - val_accuracy: 0.5242\n",
      "Epoch 63/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0478 - accuracy: 0.6267 - val_loss: 1.4049 - val_accuracy: 0.5212\n",
      "Epoch 64/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0374 - accuracy: 0.6328 - val_loss: 1.4018 - val_accuracy: 0.5230\n",
      "Epoch 65/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0379 - accuracy: 0.6332 - val_loss: 1.4014 - val_accuracy: 0.5214\n",
      "Epoch 66/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0274 - accuracy: 0.6369 - val_loss: 1.3891 - val_accuracy: 0.5280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d37b7dc070>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        callbacks=[early_stopping_cb, model_checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "213afc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 3ms/step - loss: 1.3891 - accuracy: 0.5280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3891077041625977, 0.527999997138977]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916151ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this makes it much faster and a little bit more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61f09f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
    "hidden=[100]*20\n",
    "for n_hidden in hidden:\n",
    "    model.add(keras.layers.Dense(n_hidden, activation=\"selu\",\n",
    "                                   kernel_initializer=\"lecun_normal\"))\n",
    "    \n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\",\n",
    "                                                      save_best_only=True)\n",
    "run_index =1\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_selu_logs\",\"run_selu_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "# 各チャンネルごとにスケーリングを行う\n",
    "X_train_scaled = np.zeros_like(X_train, dtype=np.float64)\n",
    "X_valid_scaled= np.zeros_like(X_valid, dtype=np.float64)\n",
    "X_test_scaled = np.zeros_like(X_test, dtype=np.float64)\n",
    "\n",
    "for i in range(3):\n",
    "    # X_trainのスケーリング\n",
    "    channel_data = X_train[:, :, :, i]\n",
    "    channel_mean = np.mean(channel_data)\n",
    "    channel_std = np.std(channel_data)\n",
    "    scaled_channel = (channel_data - channel_mean) / channel_std\n",
    "    X_train_scaled[:, :, :, i] = scaled_channel\n",
    "\n",
    "    # X_validのスケーリング\n",
    "    channel_data = X_valid[:, :, :, i]\n",
    "    scaled_channel = (channel_data - channel_mean) / channel_std\n",
    "    X_valid_scaled[:, :, :, i] = scaled_channel\n",
    "\n",
    "    # X_testのスケーリング\n",
    "    channel_data = X_test[:, :, :, i]\n",
    "    scaled_channel = (channel_data - channel_mean) / channel_std\n",
    "    X_test_scaled[:, :, :, i] = scaled_channel\n",
    "\n",
    "\n",
    "# to use selu, standardize the inputs without using batchnormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06a8fcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 16s 8ms/step - loss: 1.8991 - accuracy: 0.3196 - val_loss: 1.8204 - val_accuracy: 0.3502\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.6922 - accuracy: 0.4025 - val_loss: 1.6752 - val_accuracy: 0.3980\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.6012 - accuracy: 0.4359 - val_loss: 1.6148 - val_accuracy: 0.4396\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.5415 - accuracy: 0.4571 - val_loss: 1.6363 - val_accuracy: 0.4314\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4845 - accuracy: 0.4782 - val_loss: 1.5438 - val_accuracy: 0.4632\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4349 - accuracy: 0.4972 - val_loss: 1.5047 - val_accuracy: 0.4738\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3945 - accuracy: 0.5143 - val_loss: 1.5725 - val_accuracy: 0.4654\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3520 - accuracy: 0.5285 - val_loss: 1.4929 - val_accuracy: 0.4814\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3124 - accuracy: 0.5441 - val_loss: 1.4945 - val_accuracy: 0.4720\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2867 - accuracy: 0.5533 - val_loss: 1.4926 - val_accuracy: 0.4976\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2560 - accuracy: 0.5644 - val_loss: 1.4731 - val_accuracy: 0.5028\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2254 - accuracy: 0.5767 - val_loss: 1.5016 - val_accuracy: 0.4910\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2005 - accuracy: 0.5880 - val_loss: 1.4964 - val_accuracy: 0.4998\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1778 - accuracy: 0.5954 - val_loss: 1.4584 - val_accuracy: 0.5148\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1553 - accuracy: 0.6045 - val_loss: 1.5219 - val_accuracy: 0.5032\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1610 - accuracy: 0.6038 - val_loss: 1.4894 - val_accuracy: 0.5088\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1103 - accuracy: 0.6176 - val_loss: 1.5238 - val_accuracy: 0.5052\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0864 - accuracy: 0.6274 - val_loss: 1.5743 - val_accuracy: 0.4990\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0694 - accuracy: 0.6348 - val_loss: 1.5422 - val_accuracy: 0.5162\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0464 - accuracy: 0.6418 - val_loss: 1.5827 - val_accuracy: 0.5060\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0291 - accuracy: 0.6471 - val_loss: 1.5342 - val_accuracy: 0.5082\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0172 - accuracy: 0.6529 - val_loss: 1.6132 - val_accuracy: 0.5056\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9876 - accuracy: 0.6653 - val_loss: 1.5854 - val_accuracy: 0.5070\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9765 - accuracy: 0.6664 - val_loss: 1.5572 - val_accuracy: 0.5214\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 111.3633 - accuracy: 0.5800 - val_loss: 1.6889 - val_accuracy: 0.4116\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4006 - accuracy: 0.5041 - val_loss: 1.6092 - val_accuracy: 0.4410\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3001 - accuracy: 0.5412 - val_loss: 1.5720 - val_accuracy: 0.4560\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2374 - accuracy: 0.5651 - val_loss: 1.5772 - val_accuracy: 0.4624\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1863 - accuracy: 0.5836 - val_loss: 1.5536 - val_accuracy: 0.4768\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1965 - accuracy: 0.5845 - val_loss: 1.5486 - val_accuracy: 0.4808\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1374 - accuracy: 0.5972 - val_loss: 1.5352 - val_accuracy: 0.4968\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0983 - accuracy: 0.6141 - val_loss: 1.5570 - val_accuracy: 0.4894\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0640 - accuracy: 0.6260 - val_loss: 1.5532 - val_accuracy: 0.4948\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0371 - accuracy: 0.6395 - val_loss: 1.5416 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d36e0b4f10>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "        validation_data=(X_valid_scaled, y_valid),\n",
    "        callbacks=[early_stopping_cb, model_checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91464179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 2ms/step - loss: 1.4584 - accuracy: 0.5148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4583555459976196, 0.5148000121116638]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dcf218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is even faster but with not much change on the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "15aaa838",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
    "for o in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
    "                                   kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))    \n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_alpha_dropout_model.h5\",\n",
    "                                                      save_best_only=True)\n",
    "run_index =1\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_alpha_dropout_logs\",\"run_alpha_dropout_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ee01a6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 20s 9ms/step - loss: 1.9298 - accuracy: 0.3106 - val_loss: 1.7714 - val_accuracy: 0.3690\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.7137 - accuracy: 0.3914 - val_loss: 1.6765 - val_accuracy: 0.4132\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6297 - accuracy: 0.4272 - val_loss: 1.6685 - val_accuracy: 0.4030\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5711 - accuracy: 0.4472 - val_loss: 1.6013 - val_accuracy: 0.4372\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5198 - accuracy: 0.4678 - val_loss: 1.6205 - val_accuracy: 0.4440\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4777 - accuracy: 0.4849 - val_loss: 1.5599 - val_accuracy: 0.4708\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4333 - accuracy: 0.4964 - val_loss: 1.6103 - val_accuracy: 0.4622\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3968 - accuracy: 0.5120 - val_loss: 1.5113 - val_accuracy: 0.4736\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3645 - accuracy: 0.5235 - val_loss: 1.5895 - val_accuracy: 0.4674\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3358 - accuracy: 0.5378 - val_loss: 1.5531 - val_accuracy: 0.4812\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.3077 - accuracy: 0.5476 - val_loss: 1.5818 - val_accuracy: 0.4832\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2808 - accuracy: 0.5557 - val_loss: 1.5163 - val_accuracy: 0.4898\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2479 - accuracy: 0.5653 - val_loss: 1.6134 - val_accuracy: 0.4838\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2328 - accuracy: 0.5729 - val_loss: 1.5753 - val_accuracy: 0.4966\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2033 - accuracy: 0.5868 - val_loss: 1.5900 - val_accuracy: 0.5012\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1784 - accuracy: 0.5918 - val_loss: 1.5915 - val_accuracy: 0.4960\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1547 - accuracy: 0.6004 - val_loss: 1.6125 - val_accuracy: 0.5056\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1387 - accuracy: 0.6070 - val_loss: 1.6192 - val_accuracy: 0.4942\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.1175 - accuracy: 0.6128 - val_loss: 1.7834 - val_accuracy: 0.5012\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0950 - accuracy: 0.6216 - val_loss: 1.6061 - val_accuracy: 0.5036\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 2.0669 - accuracy: 0.4854 - val_loss: 1.6256 - val_accuracy: 0.4734\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2906 - accuracy: 0.5480 - val_loss: 1.5892 - val_accuracy: 0.4838\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2059 - accuracy: 0.5818 - val_loss: 1.6185 - val_accuracy: 0.4906\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1507 - accuracy: 0.5965 - val_loss: 1.6429 - val_accuracy: 0.4978\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1043 - accuracy: 0.6131 - val_loss: 1.7007 - val_accuracy: 0.4992\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0706 - accuracy: 0.6261 - val_loss: 1.6602 - val_accuracy: 0.4908\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0384 - accuracy: 0.6356 - val_loss: 1.6408 - val_accuracy: 0.5068\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0288 - accuracy: 0.6421 - val_loss: 1.6287 - val_accuracy: 0.4900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d36c6c6190>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "        validation_data=(X_valid_scaled, y_valid),\n",
    "        callbacks=[early_stopping_cb, model_checkpoint_cb, tensorboard_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63dcc4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = np.zeros_like(X_train, dtype=np.float64)\n",
    "X_valid_scaled= np.zeros_like(X_valid, dtype=np.float64)\n",
    "X_test_scaled = np.zeros_like(X_test, dtype=np.float64)\n",
    "\n",
    "for i in range(3):\n",
    "    # X_trainのスケーリング\n",
    "    channel_data = X_train[:, :, :, i]\n",
    "    channel_mean = np.mean(channel_data)\n",
    "    channel_std = np.std(channel_data)\n",
    "    scaled_channel = (channel_data - channel_mean) / channel_std\n",
    "    X_train_scaled[:, :, :, i] = scaled_channel\n",
    "\n",
    "    # X_validのスケーリング\n",
    "    channel_data = X_valid[:, :, :, i]\n",
    "    scaled_channel = (channel_data - channel_mean) / channel_std\n",
    "    X_valid_scaled[:, :, :, i] = scaled_channel\n",
    "\n",
    "    # X_testのスケーリング\n",
    "    channel_data = X_test[:, :, :, i]\n",
    "    scaled_channel = (channel_data - channel_mean) / channel_std\n",
    "    X_test_scaled[:, :, :, i] = scaled_channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "485e8931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2s 13ms/step - loss: 1.5113 - accuracy: 0.4736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5113234519958496, 0.47360000014305115]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slightly better ?\n",
    "model=keras.models.load_model(\"my_cifar10_alpha_dropout_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1995714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCAlphaDropout\n",
    "\n",
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)\n",
    "    \n",
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])\n",
    "# もし現在のレイヤーがkeras.layers.AlphaDropoutのインスタンスであれば、\n",
    "# 新しいレイヤーとしてMCAlphaDropout(layer.rate)を追加します。\n",
    "# 上記以外の場合は、元のレイヤーをそのまま追加します。\n",
    "# .rateはMCAlphaDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81a14dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
    "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
    "    return np.argmax(Y_probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "744dacb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2s 13ms/step\n",
      "157/157 [==============================] - 3s 17ms/step\n",
      "157/157 [==============================] - 2s 11ms/step\n",
      "157/157 [==============================] - 1s 6ms/step\n",
      "157/157 [==============================] - 2s 12ms/step\n",
      "157/157 [==============================] - 2s 14ms/step\n",
      "157/157 [==============================] - 1s 9ms/step\n",
      "157/157 [==============================] - 2s 14ms/step\n",
      "157/157 [==============================] - 2s 10ms/step\n",
      "157/157 [==============================] - 3s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4712"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
    "accuracy = np.mean(y_pred == y_valid[:, 0])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1206871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no accuracy improvement\n",
    "# BatchNormalization model may be the best in this case\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
    "for o in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
    "                                   kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))    \n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3,)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb804252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "K = keras.backend\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
    "    K.set_value(model.optimizer.learning_rate, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.learning_rate, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "183d4547",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a422cc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m----> 2\u001b[0m rates , losses \u001b[38;5;241m=\u001b[39m find_learning_rate(model, \u001b[43mX_train_scaled\u001b[49m,y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m      3\u001b[0m plot_lr_vs_loss(rates, losses)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis([\u001b[38;5;28mmin\u001b[39m(rates), \u001b[38;5;28mmax\u001b[39m(rates), \u001b[38;5;28mmin\u001b[39m(losses), (losses[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mmin\u001b[39m(losses))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1.4\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rates , losses = find_learning_rate(model, X_train_scaled,y_train, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)\n",
    "plt.axis([min(rates), max(rates), min(losses), (losses[0]+min(losses))/1.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82e6db1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[0;32m      2\u001b[0m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mset_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
    "for o in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
    "                                   kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))    \n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.1,)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e1d52ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[1;32m----> 2\u001b[0m onecycle \u001b[38;5;241m=\u001b[39m OneCycleScheduler(math\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;28mlen\u001b[39m(\u001b[43mX_train\u001b[49m) \u001b[38;5;241m/\u001b[39m batch_size) \u001b[38;5;241m*\u001b[39m n_epochs, max_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m)\n\u001b[0;32m      3\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train, epochs\u001b[38;5;241m=\u001b[39mn_epochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m      4\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39m(X_valid_scaled, y_valid),\n\u001b[0;32m      5\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39m[onecycle])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "onecycle = OneCycleScheduler(math.ceil(len(X_train_scaled) / batch_size) * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5063a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1cycle scheduling enables 15 short iterations training to have a high accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
