{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1d4396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0e82550",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42c20a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blueb\\AppData\\Local\\Temp\\ipykernel_10048\\1386261710.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  mnist1 = np.array(mnist)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mnist1 = np.array(mnist)\n",
    "print( len(mnist1[0][0]), len(mnist1[1][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e91141f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = mnist1[1][0], mnist1[1][1]\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cb0288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(mnist[0][0], mnist[0][1], \n",
    "                                                      test_size = 5000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81519b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs ={\"n_hidden\": [0,1,2,3],\n",
    "                 \"n_neurons\":[1, 100],\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2eec048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_valid = X_valid.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa616e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\blueb\\AppData\\Local\\Temp\\ipykernel_10048\\1186356165.py:14: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_reg = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 1s 946us/step - loss: nan - accuracy: 0.0976 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 844us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 838us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 842us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 857us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 844us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 846us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 859us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 861us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 847us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "573/573 [==============================] - 0s 490us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 967us/step - loss: 2.8987 - accuracy: 0.5426 - val_loss: 0.9368 - val_accuracy: 0.6910\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 884us/step - loss: 0.7180 - accuracy: 0.7839 - val_loss: 0.6029 - val_accuracy: 0.8298\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 870us/step - loss: 0.5286 - accuracy: 0.8504 - val_loss: 0.4475 - val_accuracy: 0.8730\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 867us/step - loss: 0.4244 - accuracy: 0.8743 - val_loss: 0.4419 - val_accuracy: 0.8682\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 888us/step - loss: 0.3624 - accuracy: 0.8920 - val_loss: 0.3462 - val_accuracy: 0.8986\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 869us/step - loss: 0.3246 - accuracy: 0.9034 - val_loss: 0.3589 - val_accuracy: 0.8994\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 872us/step - loss: 0.3071 - accuracy: 0.9083 - val_loss: 0.3051 - val_accuracy: 0.9102\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 875us/step - loss: 0.2903 - accuracy: 0.9116 - val_loss: 0.3812 - val_accuracy: 0.8810\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 861us/step - loss: 0.2730 - accuracy: 0.9170 - val_loss: 0.2972 - val_accuracy: 0.9080\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 902us/step - loss: 0.2638 - accuracy: 0.9189 - val_loss: 0.2801 - val_accuracy: 0.9202\n",
      "Epoch 11/60\n",
      "1146/1146 [==============================] - 1s 871us/step - loss: 0.2483 - accuracy: 0.9239 - val_loss: 0.2795 - val_accuracy: 0.9198\n",
      "Epoch 12/60\n",
      "1146/1146 [==============================] - 1s 865us/step - loss: 0.2363 - accuracy: 0.9272 - val_loss: 0.2811 - val_accuracy: 0.9190\n",
      "Epoch 13/60\n",
      "1146/1146 [==============================] - 1s 868us/step - loss: 0.2262 - accuracy: 0.9309 - val_loss: 0.2522 - val_accuracy: 0.9296\n",
      "Epoch 14/60\n",
      "1146/1146 [==============================] - 1s 883us/step - loss: 0.2172 - accuracy: 0.9336 - val_loss: 0.2525 - val_accuracy: 0.9270\n",
      "Epoch 15/60\n",
      "1146/1146 [==============================] - 1s 902us/step - loss: 0.2073 - accuracy: 0.9361 - val_loss: 0.2637 - val_accuracy: 0.9278\n",
      "Epoch 16/60\n",
      "1146/1146 [==============================] - 1s 872us/step - loss: 0.2045 - accuracy: 0.9360 - val_loss: 0.2753 - val_accuracy: 0.9190\n",
      "Epoch 17/60\n",
      "1146/1146 [==============================] - 1s 865us/step - loss: 0.1944 - accuracy: 0.9395 - val_loss: 0.2465 - val_accuracy: 0.9282\n",
      "Epoch 18/60\n",
      "1146/1146 [==============================] - 1s 870us/step - loss: 0.1892 - accuracy: 0.9423 - val_loss: 0.2535 - val_accuracy: 0.9280\n",
      "Epoch 19/60\n",
      "1146/1146 [==============================] - 1s 868us/step - loss: 0.1816 - accuracy: 0.9434 - val_loss: 0.2633 - val_accuracy: 0.9276\n",
      "Epoch 20/60\n",
      "1146/1146 [==============================] - 1s 875us/step - loss: 0.1770 - accuracy: 0.9440 - val_loss: 0.2371 - val_accuracy: 0.9316\n",
      "Epoch 21/60\n",
      "1146/1146 [==============================] - 1s 872us/step - loss: 0.1723 - accuracy: 0.9467 - val_loss: 0.2470 - val_accuracy: 0.9344\n",
      "Epoch 22/60\n",
      "1146/1146 [==============================] - 1s 872us/step - loss: 0.1649 - accuracy: 0.9482 - val_loss: 0.2443 - val_accuracy: 0.9272\n",
      "Epoch 23/60\n",
      "1146/1146 [==============================] - 1s 871us/step - loss: 0.1607 - accuracy: 0.9498 - val_loss: 0.2306 - val_accuracy: 0.9338\n",
      "Epoch 24/60\n",
      "1146/1146 [==============================] - 1s 885us/step - loss: 0.1572 - accuracy: 0.9516 - val_loss: 0.2543 - val_accuracy: 0.9320\n",
      "Epoch 25/60\n",
      "1146/1146 [==============================] - 1s 881us/step - loss: 0.1528 - accuracy: 0.9523 - val_loss: 0.2325 - val_accuracy: 0.9394\n",
      "Epoch 26/60\n",
      "1146/1146 [==============================] - 1s 875us/step - loss: 0.1485 - accuracy: 0.9530 - val_loss: 0.2271 - val_accuracy: 0.9408\n",
      "Epoch 27/60\n",
      "1146/1146 [==============================] - 1s 878us/step - loss: 0.1561 - accuracy: 0.9522 - val_loss: 0.2440 - val_accuracy: 0.9348\n",
      "Epoch 28/60\n",
      "1146/1146 [==============================] - 1s 882us/step - loss: 0.1417 - accuracy: 0.9555 - val_loss: 0.2359 - val_accuracy: 0.9386\n",
      "Epoch 29/60\n",
      "1146/1146 [==============================] - 1s 884us/step - loss: 0.1370 - accuracy: 0.9562 - val_loss: 0.2351 - val_accuracy: 0.9410\n",
      "Epoch 30/60\n",
      "1146/1146 [==============================] - 1s 898us/step - loss: 0.1344 - accuracy: 0.9585 - val_loss: 0.2577 - val_accuracy: 0.9290\n",
      "Epoch 31/60\n",
      "1146/1146 [==============================] - 1s 883us/step - loss: 0.1344 - accuracy: 0.9570 - val_loss: 0.2365 - val_accuracy: 0.9376\n",
      "Epoch 32/60\n",
      "1146/1146 [==============================] - 1s 899us/step - loss: 0.1278 - accuracy: 0.9599 - val_loss: 0.2462 - val_accuracy: 0.9358\n",
      "Epoch 33/60\n",
      "1146/1146 [==============================] - 1s 890us/step - loss: 0.1235 - accuracy: 0.9612 - val_loss: 0.2269 - val_accuracy: 0.9396\n",
      "Epoch 34/60\n",
      "1146/1146 [==============================] - 1s 921us/step - loss: 0.1231 - accuracy: 0.9602 - val_loss: 0.2378 - val_accuracy: 0.9394\n",
      "Epoch 35/60\n",
      "1146/1146 [==============================] - 1s 886us/step - loss: 0.1207 - accuracy: 0.9619 - val_loss: 0.2252 - val_accuracy: 0.9426\n",
      "Epoch 36/60\n",
      "1146/1146 [==============================] - 1s 865us/step - loss: 0.1152 - accuracy: 0.9631 - val_loss: 0.2433 - val_accuracy: 0.9420\n",
      "Epoch 37/60\n",
      "1146/1146 [==============================] - 1s 869us/step - loss: 0.1143 - accuracy: 0.9638 - val_loss: 0.2227 - val_accuracy: 0.9444\n",
      "Epoch 38/60\n",
      "1146/1146 [==============================] - 1s 872us/step - loss: 0.1111 - accuracy: 0.9639 - val_loss: 0.2454 - val_accuracy: 0.9390\n",
      "Epoch 39/60\n",
      "1146/1146 [==============================] - 1s 871us/step - loss: 0.1113 - accuracy: 0.9653 - val_loss: 0.2271 - val_accuracy: 0.9412\n",
      "Epoch 40/60\n",
      "1146/1146 [==============================] - 1s 877us/step - loss: 0.1071 - accuracy: 0.9660 - val_loss: 0.2476 - val_accuracy: 0.9368\n",
      "Epoch 41/60\n",
      "1146/1146 [==============================] - 1s 879us/step - loss: 0.1049 - accuracy: 0.9657 - val_loss: 0.2324 - val_accuracy: 0.9422\n",
      "Epoch 42/60\n",
      "1146/1146 [==============================] - 1s 870us/step - loss: 0.1023 - accuracy: 0.9674 - val_loss: 0.2409 - val_accuracy: 0.9428\n",
      "Epoch 43/60\n",
      "1146/1146 [==============================] - 1s 868us/step - loss: 0.1015 - accuracy: 0.9672 - val_loss: 0.2429 - val_accuracy: 0.9414\n",
      "Epoch 44/60\n",
      "1146/1146 [==============================] - 1s 870us/step - loss: 0.1007 - accuracy: 0.9663 - val_loss: 0.2453 - val_accuracy: 0.9436\n",
      "Epoch 45/60\n",
      "1146/1146 [==============================] - 1s 870us/step - loss: 0.0965 - accuracy: 0.9686 - val_loss: 0.2348 - val_accuracy: 0.9450\n",
      "Epoch 46/60\n",
      "1146/1146 [==============================] - 1s 876us/step - loss: 0.0978 - accuracy: 0.9691 - val_loss: 0.2561 - val_accuracy: 0.9440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/60\n",
      "1146/1146 [==============================] - 1s 871us/step - loss: 0.0903 - accuracy: 0.9707 - val_loss: 0.2393 - val_accuracy: 0.9406\n",
      "573/573 [==============================] - 0s 495us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 943us/step - loss: nan - accuracy: 0.0997 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 848us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 846us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 846us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 851us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 848us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 848us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 847us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 848us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 849us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "573/573 [==============================] - 0s 484us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 916us/step - loss: 492854912.0000 - accuracy: 0.1120 - val_loss: 2.3015 - val_accuracy: 0.1072\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 848us/step - loss: 2.3013 - accuracy: 0.1136 - val_loss: 2.3012 - val_accuracy: 0.1072\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 847us/step - loss: 2.3012 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 848us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 849us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 848us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 849us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1072\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 835us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1072\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 833us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 836us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1072\n",
      "Epoch 11/60\n",
      "1146/1146 [==============================] - 1s 829us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1072\n",
      "Epoch 12/60\n",
      "1146/1146 [==============================] - 1s 833us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 13/60\n",
      "1146/1146 [==============================] - 1s 831us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 14/60\n",
      "1146/1146 [==============================] - 1s 835us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 15/60\n",
      "1146/1146 [==============================] - 1s 834us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 16/60\n",
      "1146/1146 [==============================] - 1s 838us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 17/60\n",
      "1146/1146 [==============================] - 1s 833us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 18/60\n",
      "1146/1146 [==============================] - 1s 837us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1072\n",
      "Epoch 19/60\n",
      "1146/1146 [==============================] - 1s 837us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1072\n",
      "Epoch 20/60\n",
      "1146/1146 [==============================] - 1s 837us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1072\n",
      "Epoch 21/60\n",
      "1146/1146 [==============================] - 1s 837us/step - loss: 2.3011 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "573/573 [==============================] - 0s 484us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0980 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 951us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 950us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 957us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 957us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 952us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 951us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 955us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 980us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 974us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "573/573 [==============================] - 0s 525us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 956us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 951us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 950us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 958us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 959us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 963us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 951us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 951us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 957us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "573/573 [==============================] - 0s 513us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 897us/step - loss: 3.1949 - accuracy: 0.6629 - val_loss: 0.7214 - val_accuracy: 0.8318\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 823us/step - loss: 0.6507 - accuracy: 0.8486 - val_loss: 0.5812 - val_accuracy: 0.8714\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 824us/step - loss: 0.5247 - accuracy: 0.8762 - val_loss: 0.4918 - val_accuracy: 0.8934\n",
      "Epoch 4/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 1s 823us/step - loss: 0.4693 - accuracy: 0.8859 - val_loss: 0.4475 - val_accuracy: 0.8928\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 821us/step - loss: 0.4329 - accuracy: 0.8970 - val_loss: 0.4482 - val_accuracy: 0.8978\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 852us/step - loss: 0.3884 - accuracy: 0.9032 - val_loss: 0.3683 - val_accuracy: 0.9140\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 840us/step - loss: 0.3211 - accuracy: 0.9170 - val_loss: 0.3380 - val_accuracy: 0.9178\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 860us/step - loss: 0.2776 - accuracy: 0.9258 - val_loss: 0.3614 - val_accuracy: 0.9098\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 853us/step - loss: 0.2638 - accuracy: 0.9298 - val_loss: 0.3150 - val_accuracy: 0.9236\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 849us/step - loss: 0.2517 - accuracy: 0.9319 - val_loss: 0.2970 - val_accuracy: 0.9236\n",
      "Epoch 11/60\n",
      "1146/1146 [==============================] - 1s 856us/step - loss: 0.2397 - accuracy: 0.9345 - val_loss: 0.2783 - val_accuracy: 0.9262\n",
      "Epoch 12/60\n",
      "1146/1146 [==============================] - 1s 864us/step - loss: 0.2274 - accuracy: 0.9366 - val_loss: 0.2961 - val_accuracy: 0.9296\n",
      "Epoch 13/60\n",
      "1146/1146 [==============================] - 1s 854us/step - loss: 0.2199 - accuracy: 0.9382 - val_loss: 0.2841 - val_accuracy: 0.9284\n",
      "Epoch 14/60\n",
      "1146/1146 [==============================] - 1s 845us/step - loss: 0.2147 - accuracy: 0.9399 - val_loss: 0.3009 - val_accuracy: 0.9230\n",
      "Epoch 15/60\n",
      "1146/1146 [==============================] - 1s 853us/step - loss: 0.2092 - accuracy: 0.9403 - val_loss: 0.2986 - val_accuracy: 0.9290\n",
      "Epoch 16/60\n",
      "1146/1146 [==============================] - 1s 841us/step - loss: 0.2046 - accuracy: 0.9425 - val_loss: 0.3161 - val_accuracy: 0.9194\n",
      "Epoch 17/60\n",
      "1146/1146 [==============================] - 1s 852us/step - loss: 0.1993 - accuracy: 0.9437 - val_loss: 0.2926 - val_accuracy: 0.9260\n",
      "Epoch 18/60\n",
      "1146/1146 [==============================] - 1s 826us/step - loss: 0.1926 - accuracy: 0.9447 - val_loss: 0.2934 - val_accuracy: 0.9276\n",
      "Epoch 19/60\n",
      "1146/1146 [==============================] - 1s 837us/step - loss: 0.1912 - accuracy: 0.9448 - val_loss: 0.2899 - val_accuracy: 0.9300\n",
      "Epoch 20/60\n",
      "1146/1146 [==============================] - 1s 835us/step - loss: 0.1853 - accuracy: 0.9454 - val_loss: 0.2695 - val_accuracy: 0.9362\n",
      "Epoch 21/60\n",
      "1146/1146 [==============================] - 1s 831us/step - loss: 0.1828 - accuracy: 0.9469 - val_loss: 0.2969 - val_accuracy: 0.9294\n",
      "Epoch 22/60\n",
      "1146/1146 [==============================] - 1s 833us/step - loss: 0.1754 - accuracy: 0.9491 - val_loss: 0.2926 - val_accuracy: 0.9316\n",
      "Epoch 23/60\n",
      "1146/1146 [==============================] - 1s 839us/step - loss: 0.1794 - accuracy: 0.9472 - val_loss: 0.3069 - val_accuracy: 0.9220\n",
      "Epoch 24/60\n",
      "1146/1146 [==============================] - 1s 860us/step - loss: 0.1711 - accuracy: 0.9506 - val_loss: 0.3207 - val_accuracy: 0.9254\n",
      "Epoch 25/60\n",
      "1146/1146 [==============================] - 1s 895us/step - loss: 0.1707 - accuracy: 0.9503 - val_loss: 0.2859 - val_accuracy: 0.9342\n",
      "Epoch 26/60\n",
      "1146/1146 [==============================] - 1s 973us/step - loss: 0.1693 - accuracy: 0.9506 - val_loss: 0.2957 - val_accuracy: 0.9310\n",
      "Epoch 27/60\n",
      "1146/1146 [==============================] - 1s 894us/step - loss: 0.1657 - accuracy: 0.9515 - val_loss: 0.2938 - val_accuracy: 0.9290\n",
      "Epoch 28/60\n",
      "1146/1146 [==============================] - 1s 858us/step - loss: 0.1642 - accuracy: 0.9515 - val_loss: 0.3122 - val_accuracy: 0.9270\n",
      "Epoch 29/60\n",
      "1146/1146 [==============================] - 1s 845us/step - loss: 0.1670 - accuracy: 0.9510 - val_loss: 0.3197 - val_accuracy: 0.9322\n",
      "Epoch 30/60\n",
      "1146/1146 [==============================] - 1s 849us/step - loss: 0.1618 - accuracy: 0.9528 - val_loss: 0.2964 - val_accuracy: 0.9292\n",
      "573/573 [==============================] - 0s 497us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 846us/step - loss: 3.8410 - accuracy: 0.6384 - val_loss: 0.8504 - val_accuracy: 0.8020\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 787us/step - loss: 0.7165 - accuracy: 0.8225 - val_loss: 0.6529 - val_accuracy: 0.8528\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 783us/step - loss: 0.5611 - accuracy: 0.8600 - val_loss: 0.5354 - val_accuracy: 0.8676\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 789us/step - loss: 0.4363 - accuracy: 0.8869 - val_loss: 0.4703 - val_accuracy: 0.8836\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 783us/step - loss: 0.3588 - accuracy: 0.9041 - val_loss: 0.4590 - val_accuracy: 0.8870\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 784us/step - loss: 0.3164 - accuracy: 0.9149 - val_loss: 0.4060 - val_accuracy: 0.9070\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 789us/step - loss: 0.2917 - accuracy: 0.9196 - val_loss: 0.3388 - val_accuracy: 0.9170\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 807us/step - loss: 0.2703 - accuracy: 0.9267 - val_loss: 0.3586 - val_accuracy: 0.9150\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 864us/step - loss: 0.2585 - accuracy: 0.9276 - val_loss: 0.3673 - val_accuracy: 0.9114\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 821us/step - loss: 0.2468 - accuracy: 0.9321 - val_loss: 0.3998 - val_accuracy: 0.9004\n",
      "Epoch 11/60\n",
      "1146/1146 [==============================] - 1s 784us/step - loss: 0.2394 - accuracy: 0.9343 - val_loss: 0.3351 - val_accuracy: 0.9238\n",
      "Epoch 12/60\n",
      "1146/1146 [==============================] - 1s 834us/step - loss: 0.2276 - accuracy: 0.9376 - val_loss: 0.3458 - val_accuracy: 0.9210\n",
      "Epoch 13/60\n",
      "1146/1146 [==============================] - 1s 847us/step - loss: 0.2191 - accuracy: 0.9394 - val_loss: 0.3370 - val_accuracy: 0.9218\n",
      "Epoch 14/60\n",
      "1146/1146 [==============================] - 1s 854us/step - loss: 0.2092 - accuracy: 0.9414 - val_loss: 0.3200 - val_accuracy: 0.9282\n",
      "Epoch 15/60\n",
      "1146/1146 [==============================] - 1s 819us/step - loss: 0.2081 - accuracy: 0.9425 - val_loss: 0.3532 - val_accuracy: 0.9230\n",
      "Epoch 16/60\n",
      "1146/1146 [==============================] - 1s 783us/step - loss: 0.1985 - accuracy: 0.9440 - val_loss: 0.3473 - val_accuracy: 0.9268\n",
      "Epoch 17/60\n",
      "1146/1146 [==============================] - 1s 860us/step - loss: 0.1912 - accuracy: 0.9469 - val_loss: 0.3714 - val_accuracy: 0.9208\n",
      "Epoch 18/60\n",
      "1146/1146 [==============================] - 1s 835us/step - loss: 0.1873 - accuracy: 0.9471 - val_loss: 0.3459 - val_accuracy: 0.9252\n",
      "Epoch 19/60\n",
      "1146/1146 [==============================] - 1s 807us/step - loss: 0.1825 - accuracy: 0.9491 - val_loss: 0.3155 - val_accuracy: 0.9316\n",
      "Epoch 20/60\n",
      "1146/1146 [==============================] - 1s 828us/step - loss: 0.1776 - accuracy: 0.9497 - val_loss: 0.3283 - val_accuracy: 0.9296\n",
      "Epoch 21/60\n",
      "1146/1146 [==============================] - 1s 837us/step - loss: 0.1736 - accuracy: 0.9506 - val_loss: 0.3272 - val_accuracy: 0.9288\n",
      "Epoch 22/60\n",
      "1146/1146 [==============================] - 1s 901us/step - loss: 0.1696 - accuracy: 0.9517 - val_loss: 0.3428 - val_accuracy: 0.9302\n",
      "Epoch 23/60\n",
      "1146/1146 [==============================] - 1s 783us/step - loss: 0.1713 - accuracy: 0.9518 - val_loss: 0.3390 - val_accuracy: 0.9324\n",
      "Epoch 24/60\n",
      "1146/1146 [==============================] - 1s 777us/step - loss: 0.1634 - accuracy: 0.9528 - val_loss: 0.3393 - val_accuracy: 0.9258\n",
      "Epoch 25/60\n",
      "1146/1146 [==============================] - 1s 782us/step - loss: 0.1619 - accuracy: 0.9548 - val_loss: 0.3991 - val_accuracy: 0.9124\n",
      "Epoch 26/60\n",
      "1146/1146 [==============================] - 1s 892us/step - loss: 0.1577 - accuracy: 0.9540 - val_loss: 0.3213 - val_accuracy: 0.9336\n",
      "Epoch 27/60\n",
      "1146/1146 [==============================] - 1s 914us/step - loss: 0.1514 - accuracy: 0.9558 - val_loss: 0.3693 - val_accuracy: 0.9280\n",
      "Epoch 28/60\n",
      "1146/1146 [==============================] - 1s 843us/step - loss: 0.1499 - accuracy: 0.9568 - val_loss: 0.3364 - val_accuracy: 0.9316\n",
      "Epoch 29/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 1s 854us/step - loss: 0.1477 - accuracy: 0.9574 - val_loss: 0.3324 - val_accuracy: 0.9348\n",
      "573/573 [==============================] - 0s 517us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 856us/step - loss: 3.0821 - accuracy: 0.6551 - val_loss: 0.8464 - val_accuracy: 0.7860\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 798us/step - loss: 0.6763 - accuracy: 0.8256 - val_loss: 0.5495 - val_accuracy: 0.8698\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 795us/step - loss: 0.4812 - accuracy: 0.8719 - val_loss: 0.4591 - val_accuracy: 0.8910\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 801us/step - loss: 0.4001 - accuracy: 0.8933 - val_loss: 0.4047 - val_accuracy: 0.9088\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 833us/step - loss: 0.3465 - accuracy: 0.9061 - val_loss: 0.3976 - val_accuracy: 0.9008\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 845us/step - loss: 0.3225 - accuracy: 0.9129 - val_loss: 0.3600 - val_accuracy: 0.9122\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 807us/step - loss: 0.2877 - accuracy: 0.9200 - val_loss: 0.3429 - val_accuracy: 0.9214\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 813us/step - loss: 0.2723 - accuracy: 0.9257 - val_loss: 0.3829 - val_accuracy: 0.9188\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 904us/step - loss: 0.2559 - accuracy: 0.9297 - val_loss: 0.3278 - val_accuracy: 0.9278\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 862us/step - loss: 0.2371 - accuracy: 0.9333 - val_loss: 0.3395 - val_accuracy: 0.9244\n",
      "Epoch 11/60\n",
      "1146/1146 [==============================] - 1s 911us/step - loss: 0.2271 - accuracy: 0.9375 - val_loss: 0.3266 - val_accuracy: 0.9318\n",
      "Epoch 12/60\n",
      "1146/1146 [==============================] - 1s 957us/step - loss: 0.2205 - accuracy: 0.9384 - val_loss: 0.3180 - val_accuracy: 0.9318\n",
      "Epoch 13/60\n",
      "1146/1146 [==============================] - 1s 896us/step - loss: 0.2071 - accuracy: 0.9416 - val_loss: 0.3192 - val_accuracy: 0.9338\n",
      "Epoch 14/60\n",
      "1146/1146 [==============================] - 1s 920us/step - loss: 0.2016 - accuracy: 0.9423 - val_loss: 0.3311 - val_accuracy: 0.9230\n",
      "Epoch 15/60\n",
      "1146/1146 [==============================] - 1s 858us/step - loss: 0.1976 - accuracy: 0.9434 - val_loss: 0.3275 - val_accuracy: 0.9310\n",
      "Epoch 16/60\n",
      "1146/1146 [==============================] - 1s 911us/step - loss: 0.1944 - accuracy: 0.9445 - val_loss: 0.3256 - val_accuracy: 0.9292\n",
      "Epoch 17/60\n",
      "1146/1146 [==============================] - 1s 890us/step - loss: 0.1865 - accuracy: 0.9461 - val_loss: 0.3184 - val_accuracy: 0.9312\n",
      "Epoch 18/60\n",
      "1146/1146 [==============================] - 1s 850us/step - loss: 0.1855 - accuracy: 0.9459 - val_loss: 0.3321 - val_accuracy: 0.9302\n",
      "Epoch 19/60\n",
      "1146/1146 [==============================] - 1s 853us/step - loss: 0.1740 - accuracy: 0.9498 - val_loss: 0.3105 - val_accuracy: 0.9342\n",
      "Epoch 20/60\n",
      "1146/1146 [==============================] - 1s 856us/step - loss: 0.1745 - accuracy: 0.9501 - val_loss: 0.3443 - val_accuracy: 0.9302\n",
      "Epoch 21/60\n",
      "1146/1146 [==============================] - 1s 895us/step - loss: 0.1682 - accuracy: 0.9513 - val_loss: 0.3187 - val_accuracy: 0.9360\n",
      "Epoch 22/60\n",
      "1146/1146 [==============================] - 1s 893us/step - loss: 0.1631 - accuracy: 0.9525 - val_loss: 0.3400 - val_accuracy: 0.9268\n",
      "Epoch 23/60\n",
      "1146/1146 [==============================] - 1s 859us/step - loss: 0.1592 - accuracy: 0.9539 - val_loss: 0.3525 - val_accuracy: 0.9336\n",
      "Epoch 24/60\n",
      "1146/1146 [==============================] - 1s 822us/step - loss: 0.1556 - accuracy: 0.9545 - val_loss: 0.3201 - val_accuracy: 0.9352\n",
      "Epoch 25/60\n",
      "1146/1146 [==============================] - 1s 821us/step - loss: 0.1538 - accuracy: 0.9542 - val_loss: 0.3616 - val_accuracy: 0.9262\n",
      "Epoch 26/60\n",
      "1146/1146 [==============================] - 1s 834us/step - loss: 0.1582 - accuracy: 0.9535 - val_loss: 0.3201 - val_accuracy: 0.9378\n",
      "Epoch 27/60\n",
      "1146/1146 [==============================] - 1s 824us/step - loss: 0.1541 - accuracy: 0.9551 - val_loss: 0.3229 - val_accuracy: 0.9336\n",
      "Epoch 28/60\n",
      "1146/1146 [==============================] - 1s 822us/step - loss: 0.1471 - accuracy: 0.9570 - val_loss: 0.3357 - val_accuracy: 0.9356\n",
      "Epoch 29/60\n",
      "1146/1146 [==============================] - 1s 832us/step - loss: 0.1440 - accuracy: 0.9573 - val_loss: 0.3723 - val_accuracy: 0.9306\n",
      "573/573 [==============================] - 0s 494us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 717us/step - loss: 1.9725 - accuracy: 0.2696 - val_loss: 1.7744 - val_accuracy: 0.3046\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 618us/step - loss: 1.6974 - accuracy: 0.3350 - val_loss: 1.6593 - val_accuracy: 0.3542\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 609us/step - loss: 1.5929 - accuracy: 0.3477 - val_loss: 1.5378 - val_accuracy: 0.3748\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 602us/step - loss: 1.4724 - accuracy: 0.4050 - val_loss: 1.4213 - val_accuracy: 0.4438\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 627us/step - loss: 1.3111 - accuracy: 0.4739 - val_loss: 1.2348 - val_accuracy: 0.4924\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 692us/step - loss: 1.2316 - accuracy: 0.4823 - val_loss: 1.2117 - val_accuracy: 0.4832\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 621us/step - loss: 1.1875 - accuracy: 0.5043 - val_loss: 1.0965 - val_accuracy: 0.5700\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 667us/step - loss: 1.0645 - accuracy: 0.5755 - val_loss: 1.0521 - val_accuracy: 0.5772\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 653us/step - loss: 1.0280 - accuracy: 0.5945 - val_loss: 1.0434 - val_accuracy: 0.5882\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 632us/step - loss: 1.0048 - accuracy: 0.6190 - val_loss: 0.9749 - val_accuracy: 0.6668\n",
      "Epoch 11/60\n",
      "1146/1146 [==============================] - 1s 629us/step - loss: 0.9709 - accuracy: 0.6482 - val_loss: 0.9438 - val_accuracy: 0.6882\n",
      "Epoch 12/60\n",
      "1146/1146 [==============================] - 1s 657us/step - loss: 0.9294 - accuracy: 0.6752 - val_loss: 1.0394 - val_accuracy: 0.6314\n",
      "Epoch 13/60\n",
      "1146/1146 [==============================] - 1s 633us/step - loss: 0.8915 - accuracy: 0.6902 - val_loss: 0.8716 - val_accuracy: 0.7150\n",
      "Epoch 14/60\n",
      "1146/1146 [==============================] - 1s 679us/step - loss: 0.8198 - accuracy: 0.7357 - val_loss: 0.7626 - val_accuracy: 0.7672\n",
      "Epoch 15/60\n",
      "1146/1146 [==============================] - 1s 643us/step - loss: 0.7450 - accuracy: 0.7756 - val_loss: 0.7882 - val_accuracy: 0.7416\n",
      "Epoch 16/60\n",
      "1146/1146 [==============================] - 1s 645us/step - loss: 0.7242 - accuracy: 0.7828 - val_loss: 0.7036 - val_accuracy: 0.7932\n",
      "Epoch 17/60\n",
      "1146/1146 [==============================] - 1s 644us/step - loss: 0.6918 - accuracy: 0.7941 - val_loss: 0.7177 - val_accuracy: 0.7772\n",
      "Epoch 18/60\n",
      "1146/1146 [==============================] - 1s 666us/step - loss: 0.6701 - accuracy: 0.8030 - val_loss: 0.6863 - val_accuracy: 0.7952\n",
      "Epoch 19/60\n",
      "1146/1146 [==============================] - 1s 657us/step - loss: 0.6621 - accuracy: 0.8068 - val_loss: 0.6182 - val_accuracy: 0.8178\n",
      "Epoch 20/60\n",
      "1146/1146 [==============================] - 1s 690us/step - loss: 0.6424 - accuracy: 0.8135 - val_loss: 0.6162 - val_accuracy: 0.8230\n",
      "Epoch 21/60\n",
      "1146/1146 [==============================] - 1s 652us/step - loss: 0.6294 - accuracy: 0.8182 - val_loss: 0.6087 - val_accuracy: 0.8282\n",
      "Epoch 22/60\n",
      "1146/1146 [==============================] - 1s 663us/step - loss: 0.6256 - accuracy: 0.8183 - val_loss: 0.6046 - val_accuracy: 0.8280\n",
      "Epoch 23/60\n",
      "1146/1146 [==============================] - 1s 646us/step - loss: 0.6073 - accuracy: 0.8235 - val_loss: 0.5935 - val_accuracy: 0.8324\n",
      "Epoch 24/60\n",
      "1146/1146 [==============================] - 1s 628us/step - loss: 0.5965 - accuracy: 0.8286 - val_loss: 0.5856 - val_accuracy: 0.8312\n",
      "Epoch 25/60\n",
      "1146/1146 [==============================] - 1s 604us/step - loss: 0.5837 - accuracy: 0.8310 - val_loss: 0.5840 - val_accuracy: 0.8264\n",
      "Epoch 26/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 1s 639us/step - loss: 0.5791 - accuracy: 0.8319 - val_loss: 0.5775 - val_accuracy: 0.8290\n",
      "Epoch 27/60\n",
      "1146/1146 [==============================] - 1s 648us/step - loss: 0.5719 - accuracy: 0.8327 - val_loss: 0.6421 - val_accuracy: 0.8182\n",
      "Epoch 28/60\n",
      "1146/1146 [==============================] - 1s 641us/step - loss: 0.5673 - accuracy: 0.8344 - val_loss: 0.5645 - val_accuracy: 0.8340\n",
      "Epoch 29/60\n",
      "1146/1146 [==============================] - 1s 644us/step - loss: 0.5602 - accuracy: 0.8352 - val_loss: 0.5549 - val_accuracy: 0.8404\n",
      "Epoch 30/60\n",
      "1146/1146 [==============================] - 1s 681us/step - loss: 0.5591 - accuracy: 0.8392 - val_loss: 0.6227 - val_accuracy: 0.8160\n",
      "Epoch 31/60\n",
      "1146/1146 [==============================] - 1s 652us/step - loss: 0.5558 - accuracy: 0.8357 - val_loss: 0.5660 - val_accuracy: 0.8414\n",
      "Epoch 32/60\n",
      "1146/1146 [==============================] - 1s 632us/step - loss: 0.5520 - accuracy: 0.8392 - val_loss: 0.6521 - val_accuracy: 0.8060\n",
      "Epoch 33/60\n",
      "1146/1146 [==============================] - 1s 681us/step - loss: 0.5489 - accuracy: 0.8402 - val_loss: 0.5597 - val_accuracy: 0.8382\n",
      "Epoch 34/60\n",
      "1146/1146 [==============================] - 1s 676us/step - loss: 0.5489 - accuracy: 0.8400 - val_loss: 0.5873 - val_accuracy: 0.8218\n",
      "Epoch 35/60\n",
      "1146/1146 [==============================] - 1s 628us/step - loss: 0.5420 - accuracy: 0.8419 - val_loss: 0.5567 - val_accuracy: 0.8388\n",
      "Epoch 36/60\n",
      "1146/1146 [==============================] - 1s 619us/step - loss: 0.5408 - accuracy: 0.8418 - val_loss: 0.5780 - val_accuracy: 0.8284\n",
      "Epoch 37/60\n",
      "1146/1146 [==============================] - 1s 611us/step - loss: 0.5407 - accuracy: 0.8401 - val_loss: 0.5636 - val_accuracy: 0.8364\n",
      "Epoch 38/60\n",
      "1146/1146 [==============================] - 1s 616us/step - loss: 0.5385 - accuracy: 0.8423 - val_loss: 0.5728 - val_accuracy: 0.8270\n",
      "Epoch 39/60\n",
      "1146/1146 [==============================] - 1s 620us/step - loss: 0.5359 - accuracy: 0.8424 - val_loss: 0.5308 - val_accuracy: 0.8530\n",
      "Epoch 40/60\n",
      "1146/1146 [==============================] - 1s 629us/step - loss: 0.5288 - accuracy: 0.8463 - val_loss: 0.5554 - val_accuracy: 0.8366\n",
      "Epoch 41/60\n",
      "1146/1146 [==============================] - 1s 664us/step - loss: 0.5272 - accuracy: 0.8448 - val_loss: 0.5398 - val_accuracy: 0.8472\n",
      "Epoch 42/60\n",
      "1146/1146 [==============================] - 1s 661us/step - loss: 0.5310 - accuracy: 0.8448 - val_loss: 0.5445 - val_accuracy: 0.8444\n",
      "Epoch 43/60\n",
      "1146/1146 [==============================] - 1s 756us/step - loss: 0.5241 - accuracy: 0.8453 - val_loss: 0.5303 - val_accuracy: 0.8504\n",
      "Epoch 44/60\n",
      "1146/1146 [==============================] - 1s 668us/step - loss: 0.5223 - accuracy: 0.8474 - val_loss: 0.5362 - val_accuracy: 0.8526\n",
      "Epoch 45/60\n",
      "1146/1146 [==============================] - 1s 698us/step - loss: 0.5246 - accuracy: 0.8445 - val_loss: 0.5362 - val_accuracy: 0.8492\n",
      "Epoch 46/60\n",
      "1146/1146 [==============================] - 1s 679us/step - loss: 0.5202 - accuracy: 0.8479 - val_loss: 0.6540 - val_accuracy: 0.8114\n",
      "Epoch 47/60\n",
      "1146/1146 [==============================] - 1s 668us/step - loss: 0.5125 - accuracy: 0.8484 - val_loss: 0.5592 - val_accuracy: 0.8436\n",
      "Epoch 48/60\n",
      "1146/1146 [==============================] - 1s 737us/step - loss: 0.5191 - accuracy: 0.8472 - val_loss: 0.5167 - val_accuracy: 0.8532\n",
      "Epoch 49/60\n",
      "1146/1146 [==============================] - 1s 635us/step - loss: 0.5156 - accuracy: 0.8487 - val_loss: 0.5179 - val_accuracy: 0.8504\n",
      "Epoch 50/60\n",
      "1146/1146 [==============================] - 1s 601us/step - loss: 0.5167 - accuracy: 0.8490 - val_loss: 0.5459 - val_accuracy: 0.8488\n",
      "Epoch 51/60\n",
      "1146/1146 [==============================] - 1s 654us/step - loss: 0.5189 - accuracy: 0.8474 - val_loss: 0.5242 - val_accuracy: 0.8530\n",
      "Epoch 52/60\n",
      "1146/1146 [==============================] - 1s 680us/step - loss: 0.5116 - accuracy: 0.8499 - val_loss: 0.5250 - val_accuracy: 0.8530\n",
      "Epoch 53/60\n",
      "1146/1146 [==============================] - 1s 636us/step - loss: 0.5080 - accuracy: 0.8509 - val_loss: 0.5324 - val_accuracy: 0.8512\n",
      "Epoch 54/60\n",
      "1146/1146 [==============================] - 1s 667us/step - loss: 0.5096 - accuracy: 0.8502 - val_loss: 0.5370 - val_accuracy: 0.8510\n",
      "Epoch 55/60\n",
      "1146/1146 [==============================] - 1s 648us/step - loss: 0.5068 - accuracy: 0.8524 - val_loss: 0.7567 - val_accuracy: 0.7872\n",
      "Epoch 56/60\n",
      "1146/1146 [==============================] - 1s 659us/step - loss: 0.5051 - accuracy: 0.8531 - val_loss: 0.5334 - val_accuracy: 0.8542\n",
      "Epoch 57/60\n",
      "1146/1146 [==============================] - 1s 633us/step - loss: 0.5004 - accuracy: 0.8532 - val_loss: 0.5407 - val_accuracy: 0.8486\n",
      "Epoch 58/60\n",
      "1146/1146 [==============================] - 1s 613us/step - loss: 0.5067 - accuracy: 0.8514 - val_loss: 0.5405 - val_accuracy: 0.8398\n",
      "573/573 [==============================] - 0s 413us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 712us/step - loss: 2.0855 - accuracy: 0.2280 - val_loss: 1.8074 - val_accuracy: 0.3052\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 655us/step - loss: 1.6532 - accuracy: 0.3708 - val_loss: 1.4497 - val_accuracy: 0.4242\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 619us/step - loss: 1.4105 - accuracy: 0.4459 - val_loss: 1.3576 - val_accuracy: 0.4928\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 643us/step - loss: 1.2926 - accuracy: 0.4909 - val_loss: 1.2899 - val_accuracy: 0.4932\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 640us/step - loss: 1.2089 - accuracy: 0.5205 - val_loss: 1.2147 - val_accuracy: 0.5382\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 644us/step - loss: 1.1595 - accuracy: 0.5353 - val_loss: 1.1413 - val_accuracy: 0.5494\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 660us/step - loss: 1.1326 - accuracy: 0.5461 - val_loss: 1.1244 - val_accuracy: 0.5560\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 643us/step - loss: 1.1172 - accuracy: 0.5505 - val_loss: 1.0780 - val_accuracy: 0.5640\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 634us/step - loss: 1.1039 - accuracy: 0.5521 - val_loss: 1.1241 - val_accuracy: 0.5416\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 631us/step - loss: 1.0993 - accuracy: 0.5561 - val_loss: 1.0732 - val_accuracy: 0.5676\n",
      "Epoch 11/60\n",
      "1146/1146 [==============================] - 1s 608us/step - loss: 1.0952 - accuracy: 0.5564 - val_loss: 1.0808 - val_accuracy: 0.5674\n",
      "Epoch 12/60\n",
      "1146/1146 [==============================] - 1s 633us/step - loss: 1.0817 - accuracy: 0.5583 - val_loss: 1.0868 - val_accuracy: 0.5614\n",
      "Epoch 13/60\n",
      "1146/1146 [==============================] - 1s 620us/step - loss: 1.0783 - accuracy: 0.5653 - val_loss: 1.0804 - val_accuracy: 0.5620\n",
      "Epoch 14/60\n",
      "1146/1146 [==============================] - 1s 645us/step - loss: 1.0741 - accuracy: 0.5655 - val_loss: 1.0555 - val_accuracy: 0.5656\n",
      "Epoch 15/60\n",
      "1146/1146 [==============================] - 1s 621us/step - loss: 1.0677 - accuracy: 0.5684 - val_loss: 1.1176 - val_accuracy: 0.5546\n",
      "Epoch 16/60\n",
      "1146/1146 [==============================] - 1s 650us/step - loss: 1.0680 - accuracy: 0.5670 - val_loss: 1.0949 - val_accuracy: 0.5638\n",
      "Epoch 17/60\n",
      "1146/1146 [==============================] - 1s 646us/step - loss: 1.0694 - accuracy: 0.5708 - val_loss: 1.0473 - val_accuracy: 0.5748\n",
      "Epoch 18/60\n",
      "1146/1146 [==============================] - 1s 632us/step - loss: 1.0613 - accuracy: 0.5720 - val_loss: 1.0659 - val_accuracy: 0.5780\n",
      "Epoch 19/60\n",
      "1146/1146 [==============================] - 1s 628us/step - loss: 1.0610 - accuracy: 0.5743 - val_loss: 1.0471 - val_accuracy: 0.5838\n",
      "Epoch 20/60\n",
      "1146/1146 [==============================] - 1s 635us/step - loss: 1.0618 - accuracy: 0.5730 - val_loss: 1.0695 - val_accuracy: 0.5802\n",
      "Epoch 21/60\n",
      "1146/1146 [==============================] - 1s 630us/step - loss: 1.0520 - accuracy: 0.5787 - val_loss: 1.0799 - val_accuracy: 0.5636\n",
      "Epoch 22/60\n",
      "1146/1146 [==============================] - 1s 645us/step - loss: 1.0727 - accuracy: 0.5753 - val_loss: 1.0712 - val_accuracy: 0.5794\n",
      "Epoch 23/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 1s 628us/step - loss: 1.0658 - accuracy: 0.5808 - val_loss: 1.0689 - val_accuracy: 0.5852\n",
      "Epoch 24/60\n",
      "1146/1146 [==============================] - 1s 639us/step - loss: 1.0600 - accuracy: 0.5832 - val_loss: 1.0540 - val_accuracy: 0.5800\n",
      "Epoch 25/60\n",
      "1146/1146 [==============================] - 1s 643us/step - loss: 1.0555 - accuracy: 0.5889 - val_loss: 1.0737 - val_accuracy: 0.5862\n",
      "Epoch 26/60\n",
      "1146/1146 [==============================] - 1s 636us/step - loss: 1.0531 - accuracy: 0.5918 - val_loss: 1.0625 - val_accuracy: 0.5894\n",
      "Epoch 27/60\n",
      "1146/1146 [==============================] - 1s 632us/step - loss: 1.0460 - accuracy: 0.5948 - val_loss: 1.0385 - val_accuracy: 0.6160\n",
      "Epoch 28/60\n",
      "1146/1146 [==============================] - 1s 632us/step - loss: 1.0119 - accuracy: 0.6084 - val_loss: 0.9887 - val_accuracy: 0.6298\n",
      "Epoch 29/60\n",
      "1146/1146 [==============================] - 1s 628us/step - loss: 0.9795 - accuracy: 0.6296 - val_loss: 0.9319 - val_accuracy: 0.6542\n",
      "Epoch 30/60\n",
      "1146/1146 [==============================] - 1s 663us/step - loss: 0.9482 - accuracy: 0.6402 - val_loss: 0.9640 - val_accuracy: 0.6282\n",
      "Epoch 31/60\n",
      "1146/1146 [==============================] - 1s 678us/step - loss: 0.9351 - accuracy: 0.6481 - val_loss: 0.9238 - val_accuracy: 0.6528\n",
      "Epoch 32/60\n",
      "1146/1146 [==============================] - 1s 615us/step - loss: 0.9124 - accuracy: 0.6623 - val_loss: 0.9008 - val_accuracy: 0.6788\n",
      "Epoch 33/60\n",
      "1146/1146 [==============================] - 1s 602us/step - loss: 0.8914 - accuracy: 0.6720 - val_loss: 0.9135 - val_accuracy: 0.6696\n",
      "Epoch 34/60\n",
      "1146/1146 [==============================] - 1s 584us/step - loss: 0.8756 - accuracy: 0.6786 - val_loss: 0.8599 - val_accuracy: 0.6848\n",
      "Epoch 35/60\n",
      "1146/1146 [==============================] - 1s 592us/step - loss: 0.8624 - accuracy: 0.6896 - val_loss: 0.8233 - val_accuracy: 0.7294\n",
      "Epoch 36/60\n",
      "1146/1146 [==============================] - 1s 598us/step - loss: 0.8419 - accuracy: 0.7184 - val_loss: 0.8162 - val_accuracy: 0.7292\n",
      "Epoch 37/60\n",
      "1146/1146 [==============================] - 1s 604us/step - loss: 0.8234 - accuracy: 0.7301 - val_loss: 0.7973 - val_accuracy: 0.7332\n",
      "Epoch 38/60\n",
      "1146/1146 [==============================] - 1s 604us/step - loss: 0.8039 - accuracy: 0.7377 - val_loss: 0.8103 - val_accuracy: 0.7438\n",
      "Epoch 39/60\n",
      "1146/1146 [==============================] - 1s 622us/step - loss: 0.7889 - accuracy: 0.7447 - val_loss: 0.7927 - val_accuracy: 0.7534\n",
      "Epoch 40/60\n",
      "1146/1146 [==============================] - 1s 610us/step - loss: 0.7787 - accuracy: 0.7502 - val_loss: 0.7503 - val_accuracy: 0.7638\n",
      "Epoch 41/60\n",
      "1146/1146 [==============================] - 1s 603us/step - loss: 0.7667 - accuracy: 0.7585 - val_loss: 0.7494 - val_accuracy: 0.7604\n",
      "Epoch 42/60\n",
      "1146/1146 [==============================] - 1s 600us/step - loss: 0.7465 - accuracy: 0.7674 - val_loss: 0.7236 - val_accuracy: 0.7716\n",
      "Epoch 43/60\n",
      "1146/1146 [==============================] - 1s 619us/step - loss: 0.7295 - accuracy: 0.7726 - val_loss: 0.7050 - val_accuracy: 0.7810\n",
      "Epoch 44/60\n",
      "1146/1146 [==============================] - 1s 645us/step - loss: 0.7275 - accuracy: 0.7707 - val_loss: 0.7091 - val_accuracy: 0.7860\n",
      "Epoch 45/60\n",
      "1146/1146 [==============================] - 1s 631us/step - loss: 0.7102 - accuracy: 0.7787 - val_loss: 0.6980 - val_accuracy: 0.7750\n",
      "Epoch 46/60\n",
      "1146/1146 [==============================] - 1s 642us/step - loss: 0.7032 - accuracy: 0.7795 - val_loss: 0.7347 - val_accuracy: 0.7622\n",
      "Epoch 47/60\n",
      "1146/1146 [==============================] - 1s 626us/step - loss: 0.7095 - accuracy: 0.7759 - val_loss: 0.6955 - val_accuracy: 0.7822\n",
      "Epoch 48/60\n",
      "1146/1146 [==============================] - 1s 607us/step - loss: 0.6914 - accuracy: 0.7821 - val_loss: 0.7528 - val_accuracy: 0.7672\n",
      "Epoch 49/60\n",
      "1146/1146 [==============================] - 1s 618us/step - loss: 0.6941 - accuracy: 0.7842 - val_loss: 0.6791 - val_accuracy: 0.7966\n",
      "Epoch 50/60\n",
      "1146/1146 [==============================] - 1s 612us/step - loss: 0.6900 - accuracy: 0.7854 - val_loss: 0.7133 - val_accuracy: 0.7836\n",
      "Epoch 51/60\n",
      "1146/1146 [==============================] - 1s 654us/step - loss: 0.6863 - accuracy: 0.7854 - val_loss: 0.7621 - val_accuracy: 0.7670\n",
      "Epoch 52/60\n",
      "1146/1146 [==============================] - 1s 663us/step - loss: 0.6808 - accuracy: 0.7896 - val_loss: 0.6660 - val_accuracy: 0.7924\n",
      "Epoch 53/60\n",
      "1146/1146 [==============================] - 1s 637us/step - loss: 0.6834 - accuracy: 0.7867 - val_loss: 0.6682 - val_accuracy: 0.7900\n",
      "Epoch 54/60\n",
      "1146/1146 [==============================] - 1s 622us/step - loss: 0.6771 - accuracy: 0.7879 - val_loss: 0.6879 - val_accuracy: 0.7860\n",
      "Epoch 55/60\n",
      "1146/1146 [==============================] - 1s 625us/step - loss: 0.6772 - accuracy: 0.7902 - val_loss: 0.6869 - val_accuracy: 0.7854\n",
      "Epoch 56/60\n",
      "1146/1146 [==============================] - 1s 611us/step - loss: 0.6600 - accuracy: 0.7949 - val_loss: 0.6614 - val_accuracy: 0.7982\n",
      "Epoch 57/60\n",
      "1146/1146 [==============================] - 1s 613us/step - loss: 0.6324 - accuracy: 0.8041 - val_loss: 0.6986 - val_accuracy: 0.7958\n",
      "Epoch 58/60\n",
      "1146/1146 [==============================] - 1s 630us/step - loss: 0.6219 - accuracy: 0.8094 - val_loss: 0.6533 - val_accuracy: 0.7978\n",
      "Epoch 59/60\n",
      "1146/1146 [==============================] - 1s 626us/step - loss: 0.6072 - accuracy: 0.8165 - val_loss: 0.5869 - val_accuracy: 0.8232\n",
      "Epoch 60/60\n",
      "1146/1146 [==============================] - 1s 620us/step - loss: 0.5954 - accuracy: 0.8211 - val_loss: 0.6085 - val_accuracy: 0.8234\n",
      "573/573 [==============================] - 0s 409us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 686us/step - loss: 1.9176 - accuracy: 0.2891 - val_loss: 1.6476 - val_accuracy: 0.3446\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 611us/step - loss: 1.5547 - accuracy: 0.3782 - val_loss: 1.4657 - val_accuracy: 0.4012\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 607us/step - loss: 1.4564 - accuracy: 0.3991 - val_loss: 1.4260 - val_accuracy: 0.4132\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 620us/step - loss: 1.4030 - accuracy: 0.4231 - val_loss: 1.3560 - val_accuracy: 0.4498\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 615us/step - loss: 1.3497 - accuracy: 0.4552 - val_loss: 1.3761 - val_accuracy: 0.4354\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 613us/step - loss: 1.3214 - accuracy: 0.4715 - val_loss: 1.3269 - val_accuracy: 0.4840\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 614us/step - loss: 1.2838 - accuracy: 0.4869 - val_loss: 1.2578 - val_accuracy: 0.5124\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 602us/step - loss: 1.2622 - accuracy: 0.5000 - val_loss: 1.2264 - val_accuracy: 0.5246\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 615us/step - loss: 1.2432 - accuracy: 0.5104 - val_loss: 1.2088 - val_accuracy: 0.5314\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 621us/step - loss: 1.2220 - accuracy: 0.5220 - val_loss: 1.1849 - val_accuracy: 0.5336\n",
      "Epoch 11/60\n",
      "1146/1146 [==============================] - 1s 638us/step - loss: 1.2060 - accuracy: 0.5280 - val_loss: 1.1889 - val_accuracy: 0.5296\n",
      "Epoch 12/60\n",
      "1146/1146 [==============================] - 1s 612us/step - loss: 1.1928 - accuracy: 0.5358 - val_loss: 1.1581 - val_accuracy: 0.5594\n",
      "Epoch 13/60\n",
      "1146/1146 [==============================] - 1s 610us/step - loss: 1.1793 - accuracy: 0.5460 - val_loss: 1.1677 - val_accuracy: 0.5566\n",
      "Epoch 14/60\n",
      "1146/1146 [==============================] - 1s 606us/step - loss: 1.1694 - accuracy: 0.5501 - val_loss: 1.1662 - val_accuracy: 0.5600\n",
      "Epoch 15/60\n",
      "1146/1146 [==============================] - 1s 600us/step - loss: 1.1615 - accuracy: 0.5523 - val_loss: 1.1443 - val_accuracy: 0.5832\n",
      "Epoch 16/60\n",
      "1146/1146 [==============================] - 1s 607us/step - loss: 1.1525 - accuracy: 0.5533 - val_loss: 1.1835 - val_accuracy: 0.5442\n",
      "Epoch 17/60\n",
      "1146/1146 [==============================] - 1s 614us/step - loss: 1.1425 - accuracy: 0.5630 - val_loss: 1.1643 - val_accuracy: 0.5674\n",
      "Epoch 18/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 1s 619us/step - loss: 1.1442 - accuracy: 0.5626 - val_loss: 1.1818 - val_accuracy: 0.5662\n",
      "Epoch 19/60\n",
      "1146/1146 [==============================] - 1s 613us/step - loss: 1.1307 - accuracy: 0.5695 - val_loss: 1.1127 - val_accuracy: 0.5884\n",
      "Epoch 20/60\n",
      "1146/1146 [==============================] - 1s 615us/step - loss: 1.1263 - accuracy: 0.5730 - val_loss: 1.1057 - val_accuracy: 0.5874\n",
      "Epoch 21/60\n",
      "1146/1146 [==============================] - 1s 620us/step - loss: 1.1263 - accuracy: 0.5736 - val_loss: 1.1560 - val_accuracy: 0.5748\n",
      "Epoch 22/60\n",
      "1146/1146 [==============================] - 1s 618us/step - loss: 1.1184 - accuracy: 0.5731 - val_loss: 1.1071 - val_accuracy: 0.5924\n",
      "Epoch 23/60\n",
      "1146/1146 [==============================] - 1s 617us/step - loss: 1.1119 - accuracy: 0.5791 - val_loss: 1.1163 - val_accuracy: 0.5852\n",
      "Epoch 24/60\n",
      "1146/1146 [==============================] - 1s 629us/step - loss: 1.1189 - accuracy: 0.5787 - val_loss: 1.1319 - val_accuracy: 0.5984\n",
      "Epoch 25/60\n",
      "1146/1146 [==============================] - 1s 669us/step - loss: 1.1082 - accuracy: 0.5877 - val_loss: 1.1257 - val_accuracy: 0.5916\n",
      "Epoch 26/60\n",
      "1146/1146 [==============================] - 1s 623us/step - loss: 1.1073 - accuracy: 0.5858 - val_loss: 1.1535 - val_accuracy: 0.5810\n",
      "Epoch 27/60\n",
      "1146/1146 [==============================] - 1s 641us/step - loss: 1.1017 - accuracy: 0.5882 - val_loss: 1.1001 - val_accuracy: 0.6006\n",
      "Epoch 28/60\n",
      "1146/1146 [==============================] - 1s 624us/step - loss: 1.1003 - accuracy: 0.5892 - val_loss: 1.1154 - val_accuracy: 0.5974\n",
      "Epoch 29/60\n",
      "1146/1146 [==============================] - 1s 618us/step - loss: 1.0981 - accuracy: 0.5960 - val_loss: 1.1251 - val_accuracy: 0.5970\n",
      "Epoch 30/60\n",
      "1146/1146 [==============================] - 1s 618us/step - loss: 1.0933 - accuracy: 0.5988 - val_loss: 1.1060 - val_accuracy: 0.6014\n",
      "Epoch 31/60\n",
      "1146/1146 [==============================] - 1s 609us/step - loss: 1.0922 - accuracy: 0.5973 - val_loss: 1.1147 - val_accuracy: 0.6022\n",
      "Epoch 32/60\n",
      "1146/1146 [==============================] - 1s 610us/step - loss: 1.1187 - accuracy: 0.5879 - val_loss: 1.1542 - val_accuracy: 0.5778\n",
      "Epoch 33/60\n",
      "1146/1146 [==============================] - 1s 606us/step - loss: 1.1055 - accuracy: 0.5918 - val_loss: 1.1246 - val_accuracy: 0.6056\n",
      "Epoch 34/60\n",
      "1146/1146 [==============================] - 1s 620us/step - loss: 1.1058 - accuracy: 0.5913 - val_loss: 1.1013 - val_accuracy: 0.5958\n",
      "Epoch 35/60\n",
      "1146/1146 [==============================] - 1s 617us/step - loss: 1.0993 - accuracy: 0.5921 - val_loss: 1.1253 - val_accuracy: 0.5900\n",
      "Epoch 36/60\n",
      "1146/1146 [==============================] - 1s 619us/step - loss: 1.1035 - accuracy: 0.5897 - val_loss: 1.0830 - val_accuracy: 0.6082\n",
      "Epoch 37/60\n",
      "1146/1146 [==============================] - 1s 609us/step - loss: 1.0951 - accuracy: 0.5934 - val_loss: 1.0805 - val_accuracy: 0.6122\n",
      "Epoch 38/60\n",
      "1146/1146 [==============================] - 1s 600us/step - loss: 1.0959 - accuracy: 0.5960 - val_loss: 1.0954 - val_accuracy: 0.6060\n",
      "Epoch 39/60\n",
      "1146/1146 [==============================] - 1s 594us/step - loss: 1.0908 - accuracy: 0.5967 - val_loss: 1.1011 - val_accuracy: 0.6058\n",
      "Epoch 40/60\n",
      "1146/1146 [==============================] - 1s 608us/step - loss: 1.0851 - accuracy: 0.5982 - val_loss: 1.0886 - val_accuracy: 0.6096\n",
      "Epoch 41/60\n",
      "1146/1146 [==============================] - 1s 610us/step - loss: 1.0891 - accuracy: 0.5955 - val_loss: 1.0895 - val_accuracy: 0.6110\n",
      "Epoch 42/60\n",
      "1146/1146 [==============================] - 1s 603us/step - loss: 1.0903 - accuracy: 0.5989 - val_loss: 1.0910 - val_accuracy: 0.6026\n",
      "Epoch 43/60\n",
      "1146/1146 [==============================] - 1s 618us/step - loss: 1.0865 - accuracy: 0.6004 - val_loss: 1.1045 - val_accuracy: 0.6088\n",
      "Epoch 44/60\n",
      "1146/1146 [==============================] - 1s 661us/step - loss: 1.0872 - accuracy: 0.5971 - val_loss: 1.0977 - val_accuracy: 0.6108\n",
      "Epoch 45/60\n",
      "1146/1146 [==============================] - 1s 686us/step - loss: 1.0822 - accuracy: 0.6000 - val_loss: 1.0798 - val_accuracy: 0.6180\n",
      "Epoch 46/60\n",
      "1146/1146 [==============================] - 1s 664us/step - loss: 1.0823 - accuracy: 0.6003 - val_loss: 1.1523 - val_accuracy: 0.5816\n",
      "Epoch 47/60\n",
      "1146/1146 [==============================] - 1s 626us/step - loss: 1.0861 - accuracy: 0.6013 - val_loss: 1.0783 - val_accuracy: 0.6184\n",
      "Epoch 48/60\n",
      "1146/1146 [==============================] - 1s 624us/step - loss: 1.0797 - accuracy: 0.6037 - val_loss: 1.0674 - val_accuracy: 0.6170\n",
      "Epoch 49/60\n",
      "1146/1146 [==============================] - 1s 627us/step - loss: 1.0794 - accuracy: 0.6118 - val_loss: 1.0979 - val_accuracy: 0.6244\n",
      "Epoch 50/60\n",
      "1146/1146 [==============================] - 1s 621us/step - loss: 1.0769 - accuracy: 0.6227 - val_loss: 1.0685 - val_accuracy: 0.6438\n",
      "Epoch 51/60\n",
      "1146/1146 [==============================] - 1s 620us/step - loss: 1.0716 - accuracy: 0.6318 - val_loss: 1.0650 - val_accuracy: 0.6368\n",
      "Epoch 52/60\n",
      "1146/1146 [==============================] - 1s 628us/step - loss: 1.0677 - accuracy: 0.6374 - val_loss: 1.0471 - val_accuracy: 0.6610\n",
      "Epoch 53/60\n",
      "1146/1146 [==============================] - 1s 669us/step - loss: 1.0479 - accuracy: 0.6440 - val_loss: 1.0308 - val_accuracy: 0.6554\n",
      "Epoch 54/60\n",
      "1146/1146 [==============================] - 1s 679us/step - loss: 1.0496 - accuracy: 0.6442 - val_loss: 1.0299 - val_accuracy: 0.6602\n",
      "Epoch 55/60\n",
      "1146/1146 [==============================] - 1s 648us/step - loss: 1.0524 - accuracy: 0.6398 - val_loss: 1.0567 - val_accuracy: 0.6480\n",
      "Epoch 56/60\n",
      "1146/1146 [==============================] - 1s 641us/step - loss: 1.0472 - accuracy: 0.6447 - val_loss: 1.1235 - val_accuracy: 0.6318\n",
      "Epoch 57/60\n",
      "1146/1146 [==============================] - 1s 655us/step - loss: 1.0452 - accuracy: 0.6422 - val_loss: 1.0457 - val_accuracy: 0.6508\n",
      "Epoch 58/60\n",
      "1146/1146 [==============================] - 1s 613us/step - loss: 1.0604 - accuracy: 0.6354 - val_loss: 1.9495 - val_accuracy: 0.3454\n",
      "Epoch 59/60\n",
      "1146/1146 [==============================] - 1s 647us/step - loss: 1.0717 - accuracy: 0.6362 - val_loss: 1.0349 - val_accuracy: 0.6530\n",
      "Epoch 60/60\n",
      "1146/1146 [==============================] - 1s 683us/step - loss: 1.0336 - accuracy: 0.6479 - val_loss: 1.0954 - val_accuracy: 0.6414\n",
      "573/573 [==============================] - 0s 440us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 668us/step - loss: 3.3203 - accuracy: 0.1133 - val_loss: 2.3013 - val_accuracy: 0.1072\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 630us/step - loss: 2.3013 - accuracy: 0.1136 - val_loss: 2.3012 - val_accuracy: 0.1072\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 645us/step - loss: 2.3013 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1072\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 631us/step - loss: 2.3013 - accuracy: 0.1136 - val_loss: 2.3013 - val_accuracy: 0.1072\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 614us/step - loss: 2.3013 - accuracy: 0.1136 - val_loss: 2.3013 - val_accuracy: 0.1072\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 630us/step - loss: 2.3013 - accuracy: 0.1136 - val_loss: 2.3008 - val_accuracy: 0.1072\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 650us/step - loss: 2.3013 - accuracy: 0.1136 - val_loss: 2.3008 - val_accuracy: 0.1072\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 618us/step - loss: 2.3012 - accuracy: 0.1136 - val_loss: 2.3009 - val_accuracy: 0.1072\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 632us/step - loss: 2.3012 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 613us/step - loss: 2.3013 - accuracy: 0.1136 - val_loss: 2.3012 - val_accuracy: 0.1072\n",
      "Epoch 11/60\n",
      "1146/1146 [==============================] - 1s 620us/step - loss: 2.3012 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1072\n",
      "Epoch 12/60\n",
      "1146/1146 [==============================] - 1s 616us/step - loss: 2.3013 - accuracy: 0.1136 - val_loss: 2.3012 - val_accuracy: 0.1072\n",
      "Epoch 13/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 1s 702us/step - loss: 2.3013 - accuracy: 0.1136 - val_loss: 2.3012 - val_accuracy: 0.1072\n",
      "Epoch 14/60\n",
      "1146/1146 [==============================] - 1s 612us/step - loss: 2.3012 - accuracy: 0.1136 - val_loss: 2.3009 - val_accuracy: 0.1072\n",
      "Epoch 15/60\n",
      "1146/1146 [==============================] - 1s 612us/step - loss: 2.3013 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 16/60\n",
      "1146/1146 [==============================] - 1s 632us/step - loss: 2.3013 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1072\n",
      "Epoch 17/60\n",
      "1146/1146 [==============================] - 1s 609us/step - loss: 2.3013 - accuracy: 0.1136 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "573/573 [==============================] - 0s 410us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 663us/step - loss: 89.0316 - accuracy: 0.1116 - val_loss: 2.3013 - val_accuracy: 0.1072\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 631us/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3015 - val_accuracy: 0.1072\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 631us/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3012 - val_accuracy: 0.1072\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 626us/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 623us/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 621us/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3012 - val_accuracy: 0.1072\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 628us/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 610us/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3013 - val_accuracy: 0.1072\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 611us/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3013 - val_accuracy: 0.1072\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 626us/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3013 - val_accuracy: 0.1072\n",
      "Epoch 11/60\n",
      "1146/1146 [==============================] - 1s 620us/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3015 - val_accuracy: 0.1072\n",
      "Epoch 12/60\n",
      "1146/1146 [==============================] - 1s 616us/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3015 - val_accuracy: 0.1072\n",
      "Epoch 13/60\n",
      "1146/1146 [==============================] - 1s 636us/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3015 - val_accuracy: 0.1072\n",
      "Epoch 14/60\n",
      "1146/1146 [==============================] - 1s 636us/step - loss: 2.3013 - accuracy: 0.1123 - val_loss: 2.3015 - val_accuracy: 0.1072\n",
      "573/573 [==============================] - 0s 424us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 683us/step - loss: 51.6328 - accuracy: 0.1102 - val_loss: 2.3013 - val_accuracy: 0.1072\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 623us/step - loss: 2.3015 - accuracy: 0.1127 - val_loss: 2.3013 - val_accuracy: 0.1072\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 619us/step - loss: 2.3016 - accuracy: 0.1127 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 619us/step - loss: 2.3015 - accuracy: 0.1126 - val_loss: 2.3015 - val_accuracy: 0.1072\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 620us/step - loss: 2.3015 - accuracy: 0.1127 - val_loss: 2.3010 - val_accuracy: 0.1072\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 615us/step - loss: 2.3015 - accuracy: 0.1126 - val_loss: 2.3013 - val_accuracy: 0.1072\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 627us/step - loss: 2.3015 - accuracy: 0.1119 - val_loss: 2.3015 - val_accuracy: 0.1072\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 627us/step - loss: 2.3015 - accuracy: 0.1127 - val_loss: 2.3013 - val_accuracy: 0.1072\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 630us/step - loss: 2.3016 - accuracy: 0.1127 - val_loss: 2.3012 - val_accuracy: 0.1072\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 622us/step - loss: 2.3015 - accuracy: 0.1127 - val_loss: 2.3016 - val_accuracy: 0.1072\n",
      "Epoch 11/60\n",
      "1146/1146 [==============================] - 1s 619us/step - loss: 2.3016 - accuracy: 0.1127 - val_loss: 2.3010 - val_accuracy: 0.1072\n",
      "Epoch 12/60\n",
      "1146/1146 [==============================] - 1s 639us/step - loss: 2.3015 - accuracy: 0.1127 - val_loss: 2.3017 - val_accuracy: 0.1072\n",
      "Epoch 13/60\n",
      "1146/1146 [==============================] - 1s 655us/step - loss: 2.3015 - accuracy: 0.1121 - val_loss: 2.3012 - val_accuracy: 0.1072\n",
      "Epoch 14/60\n",
      "1146/1146 [==============================] - 1s 640us/step - loss: 2.3015 - accuracy: 0.1127 - val_loss: 2.3012 - val_accuracy: 0.1072\n",
      "Epoch 15/60\n",
      "1146/1146 [==============================] - 1s 618us/step - loss: 2.3015 - accuracy: 0.1127 - val_loss: 2.3014 - val_accuracy: 0.1072\n",
      "Epoch 16/60\n",
      "1146/1146 [==============================] - 1s 612us/step - loss: 2.3015 - accuracy: 0.1126 - val_loss: 2.3015 - val_accuracy: 0.1072\n",
      "Epoch 17/60\n",
      "1146/1146 [==============================] - 1s 606us/step - loss: 2.3016 - accuracy: 0.1124 - val_loss: 2.3013 - val_accuracy: 0.1072\n",
      "Epoch 18/60\n",
      "1146/1146 [==============================] - 1s 596us/step - loss: 2.3015 - accuracy: 0.1130 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "Epoch 19/60\n",
      "1146/1146 [==============================] - 1s 604us/step - loss: 2.3015 - accuracy: 0.1127 - val_loss: 2.3013 - val_accuracy: 0.1072\n",
      "Epoch 20/60\n",
      "1146/1146 [==============================] - 1s 615us/step - loss: 2.3015 - accuracy: 0.1127 - val_loss: 2.3010 - val_accuracy: 0.1072\n",
      "Epoch 21/60\n",
      "1146/1146 [==============================] - 1s 631us/step - loss: 2.3015 - accuracy: 0.1127 - val_loss: 2.3011 - val_accuracy: 0.1072\n",
      "573/573 [==============================] - 0s 416us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 1ms/step - loss: nan - accuracy: 0.0976 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 977us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 960us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 941us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 926us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 931us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 912us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 935us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 973us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 998us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "573/573 [==============================] - 0s 539us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 978us/step - loss: nan - accuracy: 0.0977 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 908us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 894us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 903us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 898us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 6/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 1s 905us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 899us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 915us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 918us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 922us/step - loss: nan - accuracy: 0.0978 - val_loss: nan - val_accuracy: 0.1032\n",
      "573/573 [==============================] - 0s 505us/step\n",
      "Epoch 1/60\n",
      "1146/1146 [==============================] - 1s 988us/step - loss: nan - accuracy: 0.0993 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 2/60\n",
      "1146/1146 [==============================] - 1s 909us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 3/60\n",
      "1146/1146 [==============================] - 1s 909us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 4/60\n",
      "1146/1146 [==============================] - 1s 911us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 5/60\n",
      "1146/1146 [==============================] - 1s 903us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 6/60\n",
      "1146/1146 [==============================] - 1s 915us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 7/60\n",
      "1146/1146 [==============================] - 1s 934us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 8/60\n",
      "1146/1146 [==============================] - 1s 928us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 9/60\n",
      "1146/1146 [==============================] - 1s 947us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "Epoch 10/60\n",
      "1146/1146 [==============================] - 1s 924us/step - loss: nan - accuracy: 0.0994 - val_loss: nan - val_accuracy: 0.1032\n",
      "573/573 [==============================] - 0s 510us/step\n",
      "Epoch 1/60\n",
      "1719/1719 [==============================] - 1s 784us/step - loss: 2.0326 - accuracy: 0.6982 - val_loss: 0.5525 - val_accuracy: 0.8394\n",
      "Epoch 2/60\n",
      "1719/1719 [==============================] - 1s 749us/step - loss: 0.5077 - accuracy: 0.8642 - val_loss: 0.4561 - val_accuracy: 0.8928\n",
      "Epoch 3/60\n",
      "1719/1719 [==============================] - 1s 741us/step - loss: 0.4054 - accuracy: 0.8930 - val_loss: 0.4656 - val_accuracy: 0.8802\n",
      "Epoch 4/60\n",
      "1719/1719 [==============================] - 1s 780us/step - loss: 0.3490 - accuracy: 0.9048 - val_loss: 0.3513 - val_accuracy: 0.9146\n",
      "Epoch 5/60\n",
      "1719/1719 [==============================] - 1s 779us/step - loss: 0.3228 - accuracy: 0.9122 - val_loss: 0.3284 - val_accuracy: 0.9128\n",
      "Epoch 6/60\n",
      "1719/1719 [==============================] - 1s 784us/step - loss: 0.2994 - accuracy: 0.9186 - val_loss: 0.2934 - val_accuracy: 0.9244\n",
      "Epoch 7/60\n",
      "1719/1719 [==============================] - 1s 782us/step - loss: 0.2833 - accuracy: 0.9233 - val_loss: 0.3025 - val_accuracy: 0.9236\n",
      "Epoch 8/60\n",
      "1719/1719 [==============================] - 1s 755us/step - loss: 0.2609 - accuracy: 0.9293 - val_loss: 0.3084 - val_accuracy: 0.9226\n",
      "Epoch 9/60\n",
      "1719/1719 [==============================] - 1s 754us/step - loss: 0.2554 - accuracy: 0.9295 - val_loss: 0.3099 - val_accuracy: 0.9232\n",
      "Epoch 10/60\n",
      "1719/1719 [==============================] - 1s 751us/step - loss: 0.2384 - accuracy: 0.9353 - val_loss: 0.3000 - val_accuracy: 0.9264\n",
      "Epoch 11/60\n",
      "1719/1719 [==============================] - 1s 751us/step - loss: 0.2281 - accuracy: 0.9370 - val_loss: 0.2586 - val_accuracy: 0.9360\n",
      "Epoch 12/60\n",
      "1719/1719 [==============================] - 1s 771us/step - loss: 0.2222 - accuracy: 0.9384 - val_loss: 0.2558 - val_accuracy: 0.9398\n",
      "Epoch 13/60\n",
      "1719/1719 [==============================] - 1s 774us/step - loss: 0.2133 - accuracy: 0.9412 - val_loss: 0.2736 - val_accuracy: 0.9306\n",
      "Epoch 14/60\n",
      "1719/1719 [==============================] - 1s 831us/step - loss: 0.2029 - accuracy: 0.9443 - val_loss: 0.4863 - val_accuracy: 0.8820\n",
      "Epoch 15/60\n",
      "1719/1719 [==============================] - 1s 804us/step - loss: 0.1998 - accuracy: 0.9448 - val_loss: 0.2739 - val_accuracy: 0.9358\n",
      "Epoch 16/60\n",
      "1719/1719 [==============================] - 1s 788us/step - loss: 0.1926 - accuracy: 0.9469 - val_loss: 0.2974 - val_accuracy: 0.9332\n",
      "Epoch 17/60\n",
      "1719/1719 [==============================] - 1s 756us/step - loss: 0.1864 - accuracy: 0.9479 - val_loss: 0.2501 - val_accuracy: 0.9468\n",
      "Epoch 18/60\n",
      "1719/1719 [==============================] - 1s 753us/step - loss: 0.1811 - accuracy: 0.9497 - val_loss: 0.2756 - val_accuracy: 0.9386\n",
      "Epoch 19/60\n",
      "1719/1719 [==============================] - 1s 752us/step - loss: 0.1782 - accuracy: 0.9507 - val_loss: 0.2785 - val_accuracy: 0.9426\n",
      "Epoch 20/60\n",
      "1719/1719 [==============================] - 1s 752us/step - loss: 0.1730 - accuracy: 0.9513 - val_loss: 0.2634 - val_accuracy: 0.9412\n",
      "Epoch 21/60\n",
      "1719/1719 [==============================] - 1s 751us/step - loss: 0.1681 - accuracy: 0.9528 - val_loss: 0.2826 - val_accuracy: 0.9404\n",
      "Epoch 22/60\n",
      "1719/1719 [==============================] - 1s 752us/step - loss: 0.1643 - accuracy: 0.9536 - val_loss: 0.3135 - val_accuracy: 0.9330\n",
      "Epoch 23/60\n",
      "1719/1719 [==============================] - 1s 765us/step - loss: 0.1564 - accuracy: 0.9564 - val_loss: 0.2820 - val_accuracy: 0.9416\n",
      "Epoch 24/60\n",
      "1719/1719 [==============================] - 1s 799us/step - loss: 0.1566 - accuracy: 0.9559 - val_loss: 0.2515 - val_accuracy: 0.9412\n",
      "Epoch 25/60\n",
      "1719/1719 [==============================] - 1s 865us/step - loss: 0.1512 - accuracy: 0.9571 - val_loss: 0.2573 - val_accuracy: 0.9450\n",
      "Epoch 26/60\n",
      "1719/1719 [==============================] - 1s 777us/step - loss: 0.1488 - accuracy: 0.9573 - val_loss: 0.2420 - val_accuracy: 0.9476\n",
      "Epoch 27/60\n",
      "1719/1719 [==============================] - 1s 767us/step - loss: 0.1459 - accuracy: 0.9583 - val_loss: 0.2720 - val_accuracy: 0.9456\n",
      "Epoch 28/60\n",
      "1719/1719 [==============================] - 1s 757us/step - loss: 0.1410 - accuracy: 0.9596 - val_loss: 0.2571 - val_accuracy: 0.9476\n",
      "Epoch 29/60\n",
      "1719/1719 [==============================] - 1s 850us/step - loss: 0.1378 - accuracy: 0.9608 - val_loss: 0.2707 - val_accuracy: 0.9446\n",
      "Epoch 30/60\n",
      "1719/1719 [==============================] - 2s 902us/step - loss: 0.1374 - accuracy: 0.9614 - val_loss: 0.2767 - val_accuracy: 0.9442\n",
      "Epoch 31/60\n",
      "1719/1719 [==============================] - 1s 835us/step - loss: 0.1352 - accuracy: 0.9616 - val_loss: 0.2570 - val_accuracy: 0.9480\n",
      "Epoch 32/60\n",
      "1719/1719 [==============================] - 1s 839us/step - loss: 0.1316 - accuracy: 0.9629 - val_loss: 0.2962 - val_accuracy: 0.9422\n",
      "Epoch 33/60\n",
      "1719/1719 [==============================] - 1s 824us/step - loss: 0.1365 - accuracy: 0.9622 - val_loss: 0.2764 - val_accuracy: 0.9494\n",
      "Epoch 34/60\n",
      "1719/1719 [==============================] - 1s 783us/step - loss: 0.1285 - accuracy: 0.9635 - val_loss: 0.3004 - val_accuracy: 0.9414\n",
      "Epoch 35/60\n",
      "1719/1719 [==============================] - 1s 771us/step - loss: 0.1267 - accuracy: 0.9640 - val_loss: 0.2831 - val_accuracy: 0.9458\n",
      "Epoch 36/60\n",
      "1719/1719 [==============================] - 1s 770us/step - loss: 0.1237 - accuracy: 0.9641 - val_loss: 0.2599 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001DC5FEEAEE0&gt;,\n",
       "                   n_iter=6,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000001DC73839EB0&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [1, 2, 3, 4],\n",
       "                                        &#x27;n_neurons&#x27;: [10, 120]},\n",
       "                   refit=&#x27;accuracy&#x27;,\n",
       "                   scoring={&#x27;accuracy&#x27;: make_scorer(accuracy_score)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001DC5FEEAEE0&gt;,\n",
       "                   n_iter=6,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: &lt;scipy.stats._distn_infrastructure.rv_frozen object at 0x000001DC73839EB0&gt;,\n",
       "                                        &#x27;n_hidden&#x27;: [1, 2, 3, 4],\n",
       "                                        &#x27;n_neurons&#x27;: [10, 120]},\n",
       "                   refit=&#x27;accuracy&#x27;,\n",
       "                   scoring={&#x27;accuracy&#x27;: make_scorer(accuracy_score)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001DC5FEEAEE0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasClassifier object at 0x000001DC5FEEAEE0&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x000001DC5FEEAEE0>,\n",
       "                   n_iter=6,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001DC73839EB0>,\n",
       "                                        'n_hidden': [1, 2, 3, 4],\n",
       "                                        'n_neurons': [10, 120]},\n",
       "                   refit='accuracy',\n",
       "                   scoring={'accuracy': make_scorer(accuracy_score)})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "def build_model(n_hidden=2, n_neurons=60, learning_rate = 3e-3, input_shape=[28*28]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "# that can be used as a scikit-learn regressor\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "\n",
    "\n",
    "param_distribs ={\"n_hidden\": [1,2,3,4],\n",
    "                 \"n_neurons\":[10, 120],\n",
    "                 \"learning_rate\":reciprocal(3e-4, 3e-2),\n",
    "                }\n",
    "\n",
    "scoring = {'accuracy': make_scorer(accuracy_score)}\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs , n_iter=6, cv=3,\n",
    "                                   scoring=scoring , refit='accuracy')\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=60, validation_data=[X_valid, y_valid],\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# y_pred = keras_reg.predict(X_test)\n",
    "# y_pred_classes=np.argmax(y_pred, axis=1)\n",
    "# y_test_classes=np.argmax(y_test, axis=1)\n",
    "# accuracy = keras_reg.accuracy_score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edf262c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0021638694859552284, 'n_hidden': 1, 'n_neurons': 120}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8b90afc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9292728098690919"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f720c3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1719/1719 [==============================] - 2s 992us/step - loss: 2.0118 - accuracy: 0.7506 - val_loss: 0.6708 - val_accuracy: 0.8516\n",
      "Epoch 2/60\n",
      "1719/1719 [==============================] - 2s 897us/step - loss: 0.5889 - accuracy: 0.8582 - val_loss: 0.4764 - val_accuracy: 0.8870\n",
      "Epoch 3/60\n",
      "1719/1719 [==============================] - 2s 900us/step - loss: 0.4025 - accuracy: 0.8944 - val_loss: 0.3844 - val_accuracy: 0.9092\n",
      "Epoch 4/60\n",
      "1719/1719 [==============================] - 2s 909us/step - loss: 0.3246 - accuracy: 0.9119 - val_loss: 0.3446 - val_accuracy: 0.9152\n",
      "Epoch 5/60\n",
      "1719/1719 [==============================] - 2s 882us/step - loss: 0.2953 - accuracy: 0.9201 - val_loss: 0.3190 - val_accuracy: 0.9224\n",
      "Epoch 6/60\n",
      "1719/1719 [==============================] - 2s 907us/step - loss: 0.2655 - accuracy: 0.9279 - val_loss: 0.3361 - val_accuracy: 0.9198\n",
      "Epoch 7/60\n",
      "1719/1719 [==============================] - 2s 896us/step - loss: 0.2499 - accuracy: 0.9304 - val_loss: 0.3143 - val_accuracy: 0.9310\n",
      "Epoch 8/60\n",
      "1719/1719 [==============================] - 2s 888us/step - loss: 0.2342 - accuracy: 0.9361 - val_loss: 0.2796 - val_accuracy: 0.9352\n",
      "Epoch 9/60\n",
      "1719/1719 [==============================] - 2s 910us/step - loss: 0.2193 - accuracy: 0.9382 - val_loss: 0.2892 - val_accuracy: 0.9326\n",
      "Epoch 10/60\n",
      "1719/1719 [==============================] - 2s 896us/step - loss: 0.2114 - accuracy: 0.9404 - val_loss: 0.2707 - val_accuracy: 0.9366\n",
      "Epoch 11/60\n",
      "1719/1719 [==============================] - 2s 885us/step - loss: 0.2013 - accuracy: 0.9445 - val_loss: 0.2552 - val_accuracy: 0.9386\n",
      "Epoch 12/60\n",
      "1719/1719 [==============================] - 2s 889us/step - loss: 0.1923 - accuracy: 0.9461 - val_loss: 0.2621 - val_accuracy: 0.9404\n",
      "Epoch 13/60\n",
      "1719/1719 [==============================] - 2s 902us/step - loss: 0.1845 - accuracy: 0.9481 - val_loss: 0.2642 - val_accuracy: 0.9416\n",
      "Epoch 14/60\n",
      "1719/1719 [==============================] - 2s 885us/step - loss: 0.1796 - accuracy: 0.9490 - val_loss: 0.2516 - val_accuracy: 0.9442\n",
      "Epoch 15/60\n",
      "1719/1719 [==============================] - 2s 888us/step - loss: 0.1781 - accuracy: 0.9486 - val_loss: 0.2659 - val_accuracy: 0.9438\n",
      "Epoch 16/60\n",
      "1719/1719 [==============================] - 2s 885us/step - loss: 0.1710 - accuracy: 0.9509 - val_loss: 0.2575 - val_accuracy: 0.9436\n",
      "Epoch 17/60\n",
      "1719/1719 [==============================] - 2s 888us/step - loss: 0.1671 - accuracy: 0.9524 - val_loss: 0.2933 - val_accuracy: 0.9370\n",
      "Epoch 18/60\n",
      "1719/1719 [==============================] - 2s 880us/step - loss: 0.1624 - accuracy: 0.9533 - val_loss: 0.2642 - val_accuracy: 0.9454\n",
      "Epoch 19/60\n",
      "1719/1719 [==============================] - 2s 884us/step - loss: 0.1562 - accuracy: 0.9548 - val_loss: 0.2827 - val_accuracy: 0.9354\n",
      "Epoch 20/60\n",
      "1719/1719 [==============================] - 2s 885us/step - loss: 0.1527 - accuracy: 0.9556 - val_loss: 0.2645 - val_accuracy: 0.9442\n",
      "Epoch 21/60\n",
      "1719/1719 [==============================] - 2s 884us/step - loss: 0.1486 - accuracy: 0.9570 - val_loss: 0.2694 - val_accuracy: 0.9418\n",
      "Epoch 22/60\n",
      "1719/1719 [==============================] - 2s 880us/step - loss: 0.1443 - accuracy: 0.9578 - val_loss: 0.2852 - val_accuracy: 0.9396\n",
      "Epoch 23/60\n",
      "1719/1719 [==============================] - 2s 883us/step - loss: 0.1429 - accuracy: 0.9585 - val_loss: 0.2985 - val_accuracy: 0.9388\n",
      "Epoch 24/60\n",
      "1719/1719 [==============================] - 2s 877us/step - loss: 0.1385 - accuracy: 0.9596 - val_loss: 0.2912 - val_accuracy: 0.9414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc5dbc9e50>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TrainModel(keras.Model):\n",
    "    def __init__(self, units=120,activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs) #handles standard args\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.output1 = keras.layers.Dense(10, activation=\"softmax\")\n",
    "    def call(self, inputs):\n",
    "        hidden1 = self.hidden1(inputs)\n",
    "        output1 = self.output1(hidden1)\n",
    "        return output1\n",
    "    \n",
    "model_fit1 = TrainModel()    \n",
    "learning_rate=0.0021638694859552284\n",
    "optimizer = keras.optimizers.SGD(learning_rate=learning_rate)    \n",
    "model_fit1.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n",
    "model_fit1.fit(X_train, y_train, epochs=60, validation_data=[X_valid, y_valid],\n",
    "                 callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bf0fa043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 826us/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 0.6594 - val_accuracy: 0.9514\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 1s 760us/step - loss: 0.0280 - accuracy: 0.9913 - val_loss: 0.7443 - val_accuracy: 0.9496\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 1s 759us/step - loss: 0.0318 - accuracy: 0.9901 - val_loss: 0.6892 - val_accuracy: 0.9530\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 1s 757us/step - loss: 0.0295 - accuracy: 0.9908 - val_loss: 0.6878 - val_accuracy: 0.9496\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 1s 758us/step - loss: 0.0271 - accuracy: 0.9916 - val_loss: 0.6910 - val_accuracy: 0.9520\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 1s 755us/step - loss: 0.0261 - accuracy: 0.9917 - val_loss: 0.7356 - val_accuracy: 0.9470\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 1s 753us/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.6628 - val_accuracy: 0.9522\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 1s 748us/step - loss: 0.0318 - accuracy: 0.9905 - val_loss: 0.6742 - val_accuracy: 0.9514\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 1s 753us/step - loss: 0.0290 - accuracy: 0.9912 - val_loss: 0.6963 - val_accuracy: 0.9512\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 1s 755us/step - loss: 0.0317 - accuracy: 0.9906 - val_loss: 0.7333 - val_accuracy: 0.9492\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 1s 794us/step - loss: 0.0311 - accuracy: 0.9905 - val_loss: 0.6946 - val_accuracy: 0.9556\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 1s 753us/step - loss: 0.0296 - accuracy: 0.9911 - val_loss: 0.7051 - val_accuracy: 0.9516\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 1s 755us/step - loss: 0.0279 - accuracy: 0.9912 - val_loss: 0.7160 - val_accuracy: 0.9526\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 1s 755us/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.6988 - val_accuracy: 0.9528\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 1s 753us/step - loss: 0.0386 - accuracy: 0.9890 - val_loss: 0.7114 - val_accuracy: 0.9500\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 1s 751us/step - loss: 0.0384 - accuracy: 0.9890 - val_loss: 0.7337 - val_accuracy: 0.9498\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 1s 753us/step - loss: 0.0362 - accuracy: 0.9892 - val_loss: 0.6918 - val_accuracy: 0.9506\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 1s 753us/step - loss: 0.0337 - accuracy: 0.9903 - val_loss: 0.7174 - val_accuracy: 0.9498\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 1s 754us/step - loss: 0.0366 - accuracy: 0.9893 - val_loss: 0.7284 - val_accuracy: 0.9498\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 1s 755us/step - loss: 0.0407 - accuracy: 0.9884 - val_loss: 0.7484 - val_accuracy: 0.9504\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 796us/step - loss: 0.0388 - accuracy: 0.9893 - val_loss: 0.6760 - val_accuracy: 0.9522\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 1s 744us/step - loss: 0.0294 - accuracy: 0.9911 - val_loss: 0.6986 - val_accuracy: 0.9538\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 1s 737us/step - loss: 0.0300 - accuracy: 0.9909 - val_loss: 0.7376 - val_accuracy: 0.9508\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 1s 737us/step - loss: 0.0265 - accuracy: 0.9917 - val_loss: 0.7253 - val_accuracy: 0.9494\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 1s 743us/step - loss: 0.0308 - accuracy: 0.9910 - val_loss: 0.7565 - val_accuracy: 0.9496\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 1s 736us/step - loss: 0.0240 - accuracy: 0.9923 - val_loss: 0.7367 - val_accuracy: 0.9504\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 1s 740us/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.7514 - val_accuracy: 0.9518\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 1s 743us/step - loss: 0.0263 - accuracy: 0.9918 - val_loss: 0.7219 - val_accuracy: 0.9524\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 1s 741us/step - loss: 0.0238 - accuracy: 0.9925 - val_loss: 0.7406 - val_accuracy: 0.9534\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 1s 747us/step - loss: 0.0241 - accuracy: 0.9925 - val_loss: 0.8379 - val_accuracy: 0.9454\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 1s 770us/step - loss: 0.0300 - accuracy: 0.9909 - val_loss: 0.7196 - val_accuracy: 0.9484\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 1s 747us/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.7160 - val_accuracy: 0.9492\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 1s 743us/step - loss: 0.0333 - accuracy: 0.9902 - val_loss: 0.7809 - val_accuracy: 0.9476\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 1s 744us/step - loss: 0.0330 - accuracy: 0.9903 - val_loss: 0.7666 - val_accuracy: 0.9496\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 1s 743us/step - loss: 0.0325 - accuracy: 0.9907 - val_loss: 0.7360 - val_accuracy: 0.9506\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 1s 746us/step - loss: 0.0384 - accuracy: 0.9897 - val_loss: 0.7578 - val_accuracy: 0.9528\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 1s 755us/step - loss: 0.0346 - accuracy: 0.9906 - val_loss: 0.7576 - val_accuracy: 0.9542\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 1s 791us/step - loss: 0.0307 - accuracy: 0.9908 - val_loss: 0.7621 - val_accuracy: 0.9506\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 1s 798us/step - loss: 0.0300 - accuracy: 0.9910 - val_loss: 0.7414 - val_accuracy: 0.9480\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 1s 802us/step - loss: 0.0270 - accuracy: 0.9917 - val_loss: 0.7276 - val_accuracy: 0.9506\n",
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 837us/step - loss: 0.0327 - accuracy: 0.9908 - val_loss: 0.7218 - val_accuracy: 0.9516\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 1s 747us/step - loss: 0.0288 - accuracy: 0.9917 - val_loss: 0.7772 - val_accuracy: 0.9522\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 1s 744us/step - loss: 0.0252 - accuracy: 0.9924 - val_loss: 0.7985 - val_accuracy: 0.9510\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 1s 747us/step - loss: 0.0253 - accuracy: 0.9923 - val_loss: 0.8034 - val_accuracy: 0.9508\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 1s 755us/step - loss: 0.0233 - accuracy: 0.9925 - val_loss: 0.7733 - val_accuracy: 0.9496\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 1s 747us/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.7865 - val_accuracy: 0.9534\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 1s 753us/step - loss: 0.0284 - accuracy: 0.9916 - val_loss: 0.7574 - val_accuracy: 0.9544\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 1s 757us/step - loss: 0.0294 - accuracy: 0.9911 - val_loss: 0.7869 - val_accuracy: 0.9540\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 1s 753us/step - loss: 0.0329 - accuracy: 0.9903 - val_loss: 0.7784 - val_accuracy: 0.9492\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 1s 757us/step - loss: 0.0373 - accuracy: 0.9899 - val_loss: 0.7103 - val_accuracy: 0.9532\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "for i in range(5):\n",
    "    lr = lr*np.exp(i)\n",
    "    model_fit1.optimizer = keras.optimizers.SGD(learning_rate=lr)\n",
    "    model_fit1.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n",
    "    model_fit1.fit(X_train, y_train, epochs=10, validation_data=[X_valid, y_valid],\n",
    "                   callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "954239ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 481us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model_fit1.predict(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e4b62ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f995a924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fb8e1050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9552"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341c3782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
