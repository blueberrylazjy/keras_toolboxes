{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca4a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e6a9b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "# data 正規化\n",
    "\n",
    "assert X_train_full.shape == (60000, 28, 28)\n",
    "assert X_test.shape == (10000, 28, 28)\n",
    "assert y_train_full.shape == (60000,)\n",
    "assert y_test.shape == (10000,)\n",
    "X_train_full = X_train_full.astype(np.float32)/255\n",
    "X_test = X_test.astype(np.float32)/255\n",
    "X_valid, X_train= X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train= y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51703898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one of the methods to include a preprocessing layer directly in the model\n",
    "means = np.mean(X_train, axis=0, keepdims=True)\n",
    "stds = np.std(X_train, axis=0, keepdims=True)\n",
    "eps = keras.backend.epsilon()\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Lambda(lambda inputs: (inputs- means)/ (stds + eps)),\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "# an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc8cc779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-contained custom layer\n",
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample ,axis=0, keepdims=True)\n",
    "        self.stds_ =np.std(data_sample, axis=0, keepdims=True)\n",
    "    def call(self, inputs):\n",
    "        return( inputs- self.means_)/(self.stds_+ keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "261166f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before using, pass it a data_sample \n",
    "std_layer = Standardization()\n",
    "std_layer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b54799c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 5s 2ms/step - loss: 0.9502 - accuracy: 0.6810 - val_loss: 0.6601 - val_accuracy: 0.7834\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.6066 - accuracy: 0.7886 - val_loss: 0.5585 - val_accuracy: 0.8094\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5367 - accuracy: 0.8111 - val_loss: 0.5123 - val_accuracy: 0.8260\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4987 - accuracy: 0.8236 - val_loss: 0.4829 - val_accuracy: 0.8312\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4736 - accuracy: 0.8325 - val_loss: 0.4641 - val_accuracy: 0.8406\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4549 - accuracy: 0.8389 - val_loss: 0.4497 - val_accuracy: 0.8446\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4404 - accuracy: 0.8442 - val_loss: 0.4375 - val_accuracy: 0.8486\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4284 - accuracy: 0.8489 - val_loss: 0.4292 - val_accuracy: 0.8532\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4183 - accuracy: 0.8526 - val_loss: 0.4207 - val_accuracy: 0.8566\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4094 - accuracy: 0.8552 - val_loss: 0.4142 - val_accuracy: 0.8568\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(std_layer)\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "307f13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical features using One-Hot Vectors\n",
    "# examples are shown with california housing prize data\n",
    "import os\n",
    "import pandas as pd\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\",\"housing.csv\")\n",
    "housing = pd.read_csv(HOUSING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aaa23e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a0a68276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing[\"ocean_proximity\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "99465786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = ['NEAR BAY', '<1H OCEAN', 'INLAND', 'NEAR OCEAN', 'ISLAND']\n",
    "type(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8e76885f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 1, 2, 3, 4], dtype=int64)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "indices\n",
    "# encoder用のlistを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5468874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "#　vocabにindicesを割り当て、対応付ける\n",
    "# if the categories were listed in a textfile with one category per line,\n",
    "# TextFileInitializer should be used\n",
    "num_oov_buckets=2\n",
    "# when the category does not exist, 4から数えて２つ上の数字を割り当てる意味\n",
    "# to avoid collisions or to handle changing datasets\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d21b535f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 5, 2, 2], dtype=int64)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
    "cat_indices = table.lookup(categories)\n",
    "cat_indices\n",
    "# 割り当てが終わったtableに対して.lookupを使うことでcat後のcat_indicesを作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7635c94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab)+num_oov_buckets) # one_hot化\n",
    "cat_one_hot\n",
    "# the Desert unknown bucket is located at 5, using num_oov_buckets=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27df8cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0.803156  , 0.49777734, 0.37054038],\n",
       "       [0.9118674 , 0.637642  , 0.18209696]], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uio = tf.random.uniform(shape=(2, 3))\n",
    "uio\n",
    "# an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "77ab09a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 2), dtype=float32, numpy=\n",
       "array([[0.95831835, 0.01680839],\n",
       "       [0.3156035 , 0.16013157],\n",
       "       [0.7148702 , 0.7892921 ],\n",
       "       [0.11484027, 0.33310425],\n",
       "       [0.21091413, 0.62329304],\n",
       "       [0.9865029 , 0.12230623],\n",
       "       [0.20660043, 0.87113273]], dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding categorical features using embeddings\n",
    "# embeddings is preferable on large datasets especially with categories over 50\n",
    "embedding_dim = 2\n",
    "embed_init = tf.random.uniform([len(vocab)+num_oov_buckets, embedding_dim])\n",
    "embedding_matrix = tf.Variable(embed_init) # tensor.Variableに変える\n",
    "embed_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "84fe2379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
       "array([[0.95831835, 0.01680839],\n",
       "       [0.3156035 , 0.16013157],\n",
       "       [0.7148702 , 0.7892921 ],\n",
       "       [0.11484027, 0.33310425],\n",
       "       [0.21091413, 0.62329304],\n",
       "       [0.9865029 , 0.12230623],\n",
       "       [0.20660043, 0.87113273]], dtype=float32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b44e7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([0, 5, 2, 2], dtype=int64)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
    "cat_indices = table.lookup(categories)\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "19ac0437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0.95831835, 0.01680839],\n",
       "       [0.9865029 , 0.12230623],\n",
       "       [0.7148702 , 0.7892921 ],\n",
       "       [0.7148702 , 0.7892921 ]], dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(embedding_matrix, cat_indices)\n",
    "# embedding_matrixを基にcat_indicesをembedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a321fd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[ 0.02184172,  0.02552453],\n",
       "       [ 0.01789192,  0.04401754],\n",
       "       [ 0.03224948, -0.00919038],\n",
       "       [ 0.03224948, -0.00919038]], dtype=float32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras provides a keras.layers.Embedding to hanble all of this\n",
    "embedding = keras.layers.Embedding(input_dim=len(vocab)+num_oov_buckets,\n",
    "                                   output_dim=embedding_dim)\n",
    "embedding(cat_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2941534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally create a keras model that can process categorical features\n",
    "regular_inputs = keras.layers.Input(shape=[8])\n",
    "categories = keras.layers.Input(shape=[], dtype=tf.string)\n",
    "cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
    "cat_embed = keras.layers.Embedding(input_dim=7, output_dim=2)(cat_indices)\n",
    "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
    "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
    "model = keras.models.Model(inputs=[regular_inputs, categories],\n",
    "                           outputs=[outputs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c9afa22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras preprocessing layers\n",
    "# normalization = keras.layers.Normalization()\n",
    "# discretization = keras.layers.Discretization([...])\n",
    "# pipeline = keras.layers.PreprocessingStage([normalization, discretization])\n",
    "# pipeline.adapt(data_sample)\n",
    "# P562"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Transform\n",
    "#P564-567"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
