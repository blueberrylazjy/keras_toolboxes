{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26ab2d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bffceea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataset entirely in RAM\n",
    "X= tf.range(10)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20545238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset\n",
    "# from_tensor_slices(X) takes elements all from X and pass it to tf.data.Dataset\n",
    "# to create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e4f9e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2983acd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "repeated_dataset = dataset.repeat(3)\n",
    "for item in repeated_dataset:\n",
    "    print(item)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07a1e3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "batch = dataset.batch(7)\n",
    "for item in batch:\n",
    "    print(item)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47275b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "batch = dataset.batch(7, drop_remainder=True)\n",
    "for item in batch:\n",
    "    print(item)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e7870b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
      "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
      "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
      "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
      "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.repeat(3).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "# repeat(n) method returns a new dataset that will repeat the items of the original\n",
    "# dataset n times\n",
    "\n",
    "#batch(n) method creates a new dataset group the items of the previous dataset\n",
    "# in batches of n items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ecd1ae8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# transform the items by calling the map() method\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "dataset = dataset.map(lambda x:x*2)\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "# this function could be used for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "474e149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(12, shape=(), dtype=int32)\n",
      "tf.Tensor(14, shape=(), dtype=int32)\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "tf.Tensor(18, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# num_parallel_calls help spawn multiple threads\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "def preprocess(x):\n",
    "    return x * 2\n",
    "processed_dataset = dataset.map(preprocess, \n",
    "                                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "# tf.data.experimental.AUTOTUNE を使用すると自動的に最適なスレッド数を選択する\n",
    "for item in processed_dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48b2338a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# applt() method applies a transformation to the dataset as a whole\n",
    "Xn= tf.Variable([[1.,2.,3.],[1.,2.,3.]])\n",
    "dataset = tf.data.Dataset.from_tensor_slices(Xn)\n",
    "dataset = dataset.apply(tf.data.experimental.unbatch())\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a9d134d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# with a filter(lambda x: ...) method, it is also possible to filter the dataset\n",
    "dataset = dataset.filter(lambda x:x<5)\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b539691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for item in dataset.take(3):\n",
    "    print(item)\n",
    "# take limits the indices to be shown "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39759e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f535f838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 5 1 7 0 8 9], shape=(7,), dtype=int64)\n",
      "tf.Tensor([0 4 3 1 5 6 4], shape=(7,), dtype=int64)\n",
      "tf.Tensor([6 7 2 9 0 3 3], shape=(7,), dtype=int64)\n",
      "tf.Tensor([2 8 4 6 8 9 7], shape=(7,), dtype=int64)\n",
      "tf.Tensor([5 1], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#Shuffling the Data\n",
    "# buffer_size hyperparameter determines the size of data to be taken out of the dataset\n",
    "# at one time, setting it larger is preferable but may encounter RAM exceeding\n",
    "dataset = tf.data.Dataset.range(10).repeat(3)\n",
    "dataset = dataset.shuffle(buffer_size=5, seed=42, reshuffle_each_iteration=False).batch(7)\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "# reshuffle_each_iteration = False makes sure that a shuffled dataset keeps its order\n",
    "# when repeat() method is called on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "183d7204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interleaving lines from multiple files\n",
    "# P 536-537\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a22d5864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target.reshape(-1,1),\n",
    "                                                              random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full,\n",
    "                                                      random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_mean = scaler.mean_\n",
    "X_std = scaler.scale_\n",
    "# split into multiple files (especially for big datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "94981b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11610"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a21a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "    housing_dir = os.path.join(\"datasets\", \"housing\")  # ファイルを保存するディレクトリのパスを指定します\n",
    "    os.makedirs(housing_dir, exist_ok=True)  # housing_dirで指定されたディレクトリを作成します（既に存在している場合はスキップします）\n",
    "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")  # ファイルのパスのフォーマットを指定します\n",
    "\n",
    "    filepaths = []  # 保存された各ファイルのパスを格納するリストを初期化します\n",
    "    m = len(data)  # データの総数を取得します\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        # データをn_partsで指定された数に分割し、各パートごとに処理を行います\n",
    "        part_csv = path_format.format(name_prefix, file_idx)  # パートごとのCSVファイルのパスを生成します\n",
    "        filepaths.append(part_csv)  # パートごとのCSVファイルのパスをリストに追加します\n",
    "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "            # パートごとのCSVファイルを書き込みモードで開きます\n",
    "            if header is not None:\n",
    "                f.write(header)  # ヘッダー行を書き込みます\n",
    "                f.write(\"\\n\")\n",
    "            for row_idx in row_indices:\n",
    "                # 各パートの行のインデックスに対応するデータをCSVファイルに書き込みます\n",
    "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                #repr()関数は、オブジェクトを表す文字列を返します。\n",
    "                # joinでリスト内の要素をカンマで結合して一つの文字列にする\n",
    "                # example [1,2,3,4]→\"1,2,3,4\"\n",
    "                f.write(\"\\n\") #改行文字\n",
    "    return filepaths  # 保存された各ファイルのパスのリストを返します\n",
    "# open の \"wt\"は\n",
    "#\"w\": 書き込みモードを指定します。ファイルが存在する場合は、既存の内容を削除して\n",
    "# 新しい内容を書き込みます。存在しない場合は、新しいファイルを作成して書き込みます。\n",
    "\n",
    "#\"t\": テキストモードを指定します。テキストモードでは、ファイルをテキストとして\n",
    "#扱います。これにより、テキストデータをエンコード・デコードする機能が有効になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc715355",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.c_[X_train, y_train]\n",
    "valid_data = np.c_[X_valid, y_valid]\n",
    "test_data = np.c_[X_test, y_test]\n",
    "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
    "header = \",\".join(header_cols)\n",
    "\n",
    "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
    "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0b9e5935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.6812</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.192201</td>\n",
       "      <td>1.022284</td>\n",
       "      <td>1392.0</td>\n",
       "      <td>3.877437</td>\n",
       "      <td>36.06</td>\n",
       "      <td>-119.01</td>\n",
       "      <td>0.47700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5313</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.039384</td>\n",
       "      <td>1.193493</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>2.679795</td>\n",
       "      <td>35.14</td>\n",
       "      <td>-119.46</td>\n",
       "      <td>0.45800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.4801</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3.977155</td>\n",
       "      <td>1.185877</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>1.360332</td>\n",
       "      <td>37.80</td>\n",
       "      <td>-122.44</td>\n",
       "      <td>5.00001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  1.6812      25.0  4.192201   1.022284      1392.0  3.877437     36.06   \n",
       "1  2.5313      30.0  5.039384   1.193493      1565.0  2.679795     35.14   \n",
       "2  3.4801      52.0  3.977155   1.185877      1310.0  1.360332     37.80   \n",
       "\n",
       "   Longitude  MedianHouseValue  \n",
       "0    -119.01           0.47700  \n",
       "1    -119.46           0.45800  \n",
       "2    -122.44           5.00001  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tewt = pd.read_csv(os.path.join(\"datasets\",\"housing\",\"my_test_00.csv\"))\n",
    "tewt.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f9bdb694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
      "3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442\n",
      "5.3275,5.0,6.490059642147117,0.9910536779324056,3464.0,3.4433399602385686,33.69,-117.39,1.687\n",
      "3.1,29.0,7.5423728813559325,1.5915254237288134,1328.0,2.2508474576271187,38.44,-122.98,1.621\n",
      "7.1736,12.0,6.289002557544757,0.9974424552429667,1054.0,2.6956521739130435,33.55,-117.7,2.621\n"
     ]
    }
   ],
   "source": [
    "with open(train_filepaths[0]) as f:\n",
    "    for i in range(5):\n",
    "        print(f.readline(), end=\"\")\n",
    "#書き込んだファイルの様子\n",
    "# , で区切ってexcelで見れる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "28dbd786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datasets\\\\housing\\\\my_train_00.csv',\n",
       " 'datasets\\\\housing\\\\my_train_01.csv',\n",
       " 'datasets\\\\housing\\\\my_train_02.csv']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filepaths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "64cbb6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2, 3, 4]), array([5, 6, 7, 8, 9]), array([10, 11, 12, 13, 14])]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array_split(np.arange(100), 20))[:3] \n",
    "# np.arange(100) を 20の len5 のarrayに分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "83477ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'4.2083,44.0,5.323204419889502,0.9171270718232044,846.0,2.3370165745856353,37.47,-122.2,2.782'\n",
      "b'4.1812,52.0,5.701388888888889,0.9965277777777778,692.0,2.4027777777777777,33.73,-118.31,3.215'\n",
      "b'3.6875,44.0,4.524475524475524,0.993006993006993,457.0,3.195804195804196,34.04,-118.15,1.625'\n",
      "b'3.3456,37.0,4.514084507042254,0.9084507042253521,458.0,3.2253521126760565,36.67,-121.7,2.526'\n",
      "b'3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442'\n"
     ]
    }
   ],
   "source": [
    "# interleave steps\n",
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)\n",
    "# list_files returns a dataset that shuffles the file paths\n",
    "# set shuffle = False ,stops this\n",
    "\n",
    "# interleave the lines with five files at a time\n",
    "n_readers = 5\n",
    "dataset = filepath_dataset.interleave(lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "                                      cycle_length = n_readers)\n",
    "#.skip(1) skips the first line because those are titles\n",
    "\n",
    "# .interleave method create a dataset that will pull five file paths from the\n",
    "# filepath_dataset\n",
    "\n",
    "for line in dataset.take(5):\n",
    "    print(line.numpy())\n",
    "# these are the first rows( hearder ignored) of five CSV files, chosen randomly\n",
    "# still have to be scaled and parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "18277cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 8 # X_train.shape[-1]\n",
    "\n",
    "def preprocess(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    x = tf.stack(fields[:-1]) # stack these tensors into a 1D array without the target\n",
    "    y = tf.stack(fields[-1:]) # stach the target\n",
    "    return (x - X_mean) / X_std, y\n",
    "# tf.io.decode_csv(a , b)\n",
    "# a is the line to parse\n",
    "# b is an array containing the default value for each column in the CSV file\n",
    "# b tells tf.io.decode_csv tells the number of columns, types and default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9047cc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " <tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choke = [0.] * 8 + [tf.constant([], dtype=tf.float32)]\n",
    "choke\n",
    "# +[tf.constant([], dtype=ft.float32)] turns [0.] * 8 to a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "da8486e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choke = [0.] * 8 \n",
    "choke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7f16d3e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([ 0.16579159,  1.216324  , -0.05204564, -0.39215982, -0.5277444 ,\n",
       "        -0.2633488 ,  0.8543046 , -1.3072058 ], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(b'4.2083,44.0,5.3232,0.9171,846.0,2.3370,37.47,-122.2,2.782')\n",
    "# bはバイト文字列を意味する　データ形を宣言している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5c736aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full preprocessing steps\n",
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5 , batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths)\n",
    "    dataset = filepath_dataset.interleave(lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "                                           cycle_length = n_readers, num_parallel_calls = n_read_threads)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls = n_read_threads)\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size).repeat(repeat)\n",
    "    return dataset.batch(batch_size).prefetch(1)\n",
    "# interpretation of this code P 541\n",
    "# about prefetch , multithreaded loading and preprocessing\n",
    "# P542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "17983d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'datasets\\\\housing\\\\my_test_00.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_test_01.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_test_05.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_test_06.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_test_04.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_test_02.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_test_07.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_test_03.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_test_08.csv', shape=(), dtype=string)\n",
      "tf.Tensor(b'datasets\\\\housing\\\\my_test_09.csv', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "test_tt = tf.data.Dataset.list_files(test_filepaths)\n",
    "test_tt = filepath_dataset.interleave(lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "                                           cycle_length = n_readers, num_parallel_calls = n_read_threads)\n",
    "for item in test_tt:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3b4b7bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the dataset with tf.keras\n",
    "train_set = csv_reader_dataset(train_filepaths, repeat=None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths)\n",
    "test_set = csv_reader_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2104f4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "90164d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(300, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "76efa695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "362/362 [==============================] - 2s 2ms/step - loss: 1.8307 - val_loss: 0.7815\n",
      "Epoch 2/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.7107 - val_loss: 0.6678\n",
      "Epoch 3/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.6437 - val_loss: 0.6235\n",
      "Epoch 4/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.6070 - val_loss: 0.5879\n",
      "Epoch 5/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.5733 - val_loss: 0.5582\n",
      "Epoch 6/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.5484 - val_loss: 0.5337\n",
      "Epoch 7/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.5241 - val_loss: 0.5132\n",
      "Epoch 8/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.5058 - val_loss: 0.4959\n",
      "Epoch 9/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.4907 - val_loss: 0.4812\n",
      "Epoch 10/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 0.4759 - val_loss: 0.4692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22448fd3a00>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.SGD(learning_rate=1e-3), loss=\"mse\")\n",
    "batch_size=32\n",
    "model.fit(train_set, steps_per_epoch = len(X_train)// batch_size, epochs=10,\n",
    "          validation_data = valid_set)\n",
    "#steps_per_epochは一ステップの計算数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "df1dc82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 1s 403us/step - loss: 0.4547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.45471519231796265"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_set, steps=len(X_test)//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b6124cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(96, 1)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_set = test_set.take(3).map(lambda X,y: X) #pretend we have new 3 instances\n",
    "# lambda関数は test_setのlabel部分を取り除くのに使う\n",
    "model.predict(new_set).shape\n",
    "# batch_size 32 * 3 = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b816641e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.9144926],\n",
       "       [2.387704 ],\n",
       "       [1.0466435]], dtype=float32)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_set = test_set.take(3)\n",
    "# kerasは自動的にlabelを無視する\n",
    "model.predict(new_set)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1996701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
